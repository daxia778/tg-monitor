"""
Web Dashboard V2 â€” FastAPI åç«¯
æä¾› REST API ä¾›å‰ç«¯å±•ç¤ºç›‘æ§æ•°æ®
"""
from __future__ import annotations

import csv
import io
import logging
from datetime import datetime, timezone, timedelta
from pathlib import Path
from typing import Optional

from fastapi import FastAPI, Query, Depends
from fastapi.staticfiles import StaticFiles
from fastapi.responses import HTMLResponse, FileResponse, StreamingResponse

from .config import load_config
from .database import Database

logger = logging.getLogger("tg-monitor.web")

app = FastAPI(title="TG Monitor Dashboard", version="2.0.0")

# å…¨å±€çŠ¶æ€
_db: Optional[Database] = None
_config: Optional[dict] = None

STATIC_DIR = Path(__file__).parent / "web" / "static"


async def get_db() -> Database:
    global _db, _config
    if _db is None:
        _config = load_config()
        _db = Database(_config["database"]["path"])
        await _db.connect()
    return _db


@app.on_event("startup")
async def startup():
    await get_db()
    logger.info("ğŸŒ Dashboard V2 API å·²å¯åŠ¨")


@app.on_event("shutdown")
async def shutdown():
    if _db:
        await _db.close()


# â”€â”€â”€ é™æ€æ–‡ä»¶ & é¦–é¡µ â”€â”€â”€
app.mount("/static", StaticFiles(directory=str(STATIC_DIR)), name="static")


@app.get("/", response_class=HTMLResponse)
async def index():
    return FileResponse(STATIC_DIR / "index.html")


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# API ç«¯ç‚¹
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

@app.get("/api/health")
async def api_health(db: Database = Depends(get_db)):
    """å¥åº·æ£€æŸ¥ (å¢å¼ºç‰ˆ)"""
    try:
        total = await db.get_message_count()
        groups = await db.get_groups()
        
        # è·å–æ•°æ®åº“æ–‡ä»¶å¤§å°
        db_path = Path(_config["database"]["path"]) if _config else Path("data/tg_monitor.db")
        db_size_mb = round(db_path.stat().st_size / (1024 * 1024), 2) if db_path.exists() else 0
        
        # è·å–æœ€æ–°çš„æ¶ˆæ¯æ—¶é—´
        recent = await db.get_recent_messages(limit=1)
        last_sync = recent[0]["date"] if recent else "never"
        
        return {
            "status": "ok", 
            "messages": total, 
            "groups": len(groups),
            "db_size_mb": db_size_mb,
            "last_sync": last_sync,
            "version": "2.0.1"
        }
    except Exception as e:
        logger.error(f"Health check failed: {e}")
        return {"status": "error", "detail": str(e)}


@app.get("/api/overview")
async def api_overview(db: Database = Depends(get_db)):
    """æ€»è§ˆæ•°æ®"""
    now = datetime.now(timezone.utc)

    total = await db.get_message_count()
    h1 = await db.get_message_count(since=(now - timedelta(hours=1)).isoformat(timespec='seconds'))
    h24 = await db.get_message_count(since=(now - timedelta(hours=24)).isoformat(timespec='seconds'))
    h7d = await db.get_message_count(since=(now - timedelta(days=7)).isoformat(timespec='seconds'))
    groups = await db.get_groups()

    # é“¾æ¥å’Œæ‘˜è¦ç»Ÿè®¡
    links = await db.get_links(limit=1)
    summaries = await db.get_latest_summaries(limit=1)

    return {
        "total_messages": total,
        "last_1h": h1,
        "last_24h": h24,
        "last_7d": h7d,
        "group_count": len(groups),
        "model": _config.get("ai", {}).get("model", "?") if _config else "?",
        "alerts_enabled": _config.get("alerts", {}).get("enabled", False) if _config else False,
    }


@app.get("/api/trends")
async def api_trends(hours: int = Query(default=72, ge=1, le=720), db: Database = Depends(get_db)):
    """æ¶ˆæ¯è¶‹åŠ¿æ•°æ®"""
    rows = await db.get_message_trends(hours=hours)
    return {"data": [{"hour": r["hour"], "count": r["count"]} for r in rows]}


@app.get("/api/comparison")
async def api_comparison(db: Database = Depends(get_db)):
    """ä»Šå¤© vs æ˜¨å¤©æ¶ˆæ¯é‡å¯¹æ¯”"""
    return await db.get_hourly_comparison()


@app.get("/api/heatmap")
async def api_heatmap(days: int = Query(default=30), db: Database = Depends(get_db)):
    """æ´»è·ƒåº¦çƒ­åŠ›å›¾æ•°æ®"""
    data = await db.get_heatmap_data(days=days)
    return {"data": data}


@app.get("/api/groups")
async def api_groups(hours: int = Query(default=24), db: Database = Depends(get_db)):
    """ç¾¤ç»„ç»Ÿè®¡"""
    now = datetime.now(timezone.utc)
    since = (now - timedelta(hours=hours)).isoformat(timespec='seconds')
    stats = await db.get_stats(since=since)
    return {"data": stats}


@app.get("/api/groups/{group_id}")
async def api_group_detail(group_id: int, hours: int = Query(default=24), db: Database = Depends(get_db)):
    """ç¾¤ç»„è¯¦æƒ… â€” æ¶ˆæ¯åˆ—è¡¨"""
    messages = await db.get_group_messages(group_id, hours=hours, limit=200)
    trends = await db.get_group_trends(group_id, hours=max(hours, 72))

    # ç¾¤ç»„åŸºæœ¬ä¿¡æ¯
    groups = await db.get_groups()
    group_info = next((g for g in groups if g["id"] == group_id), {})

    # æ´»è·ƒç”¨æˆ·
    now = datetime.now(timezone.utc)
    since = (now - timedelta(hours=hours)).isoformat(timespec='seconds')
    top = await db.get_top_senders(group_id=group_id, since=since, limit=5)

    return {
        "info": group_info,
        "messages": messages,
        "trends": trends,
        "top_senders": top,
    }


@app.get("/api/top_senders")
async def api_top_senders(hours: int = Query(default=24), limit: int = Query(default=10), db: Database = Depends(get_db)):
    """æœ€æ´»è·ƒç”¨æˆ·"""
    now = datetime.now(timezone.utc)
    since = (now - timedelta(hours=hours)).isoformat(timespec='seconds')
    top = await db.get_top_senders(since=since, limit=limit)
    return {"data": top}


@app.get("/api/links")
async def api_links(limit: int = Query(default=30), db: Database = Depends(get_db)):
    """æœ€æ–°é“¾æ¥"""
    config = _config or load_config()
    
    # åŠ¨æ€åŠ è½½è¿‡æ»¤åŸŸåï¼Œé»˜è®¤è¿‡æ»¤å†…éƒ¨çŸ­é“¾æ¥
    block_domains = config.get("filtering", {}).get(
        "block_domains", 
        ["t.me", "telegram.me", "telegram.org", "telegra.ph", "telegram.dog"]
    )
    
    links = await db.get_links(limit=limit, block_domains=block_domains)
    return {"data": links}


@app.get("/api/search")
async def api_search(q: str = Query(..., min_length=1), limit: int = Query(default=50), db: Database = Depends(get_db)):
    """æœç´¢æ¶ˆæ¯"""
    results = await db.search_messages(q, limit=limit)
    return {"data": results, "total": len(results)}


@app.get("/api/alerts_config")
async def api_alerts_config(db: Database = Depends(get_db)):
    """å‘Šè­¦é…ç½®"""
    config = _config or load_config()
    alerts = config.get("alerts", {})
    return {
        "enabled": alerts.get("enabled", False),
        "keywords": alerts.get("keywords", []),
    }


@app.get("/api/recent_messages")
async def api_recent_messages(
    limit: int = Query(default=100, le=500),
    group_id: Optional[int] = Query(default=None),
    db: Database = Depends(get_db)
):
    """æœ€æ–°æ¶ˆæ¯æµï¼ˆå§‹ç»ˆè¿”å›æœ€æ–°çš„ N æ¡ï¼‰"""
    messages = await db.get_recent_messages(limit=limit, group_id=group_id)

    groups = await db.get_groups()
    group_map = {g["id"]: g["title"] for g in groups}
    for msg in messages:
        msg["group_title"] = group_map.get(msg.get("group_id", 0), "æœªçŸ¥")

    # æ£€æŸ¥æ˜¯å¦å‘½ä¸­å‘Šè­¦å…³é”®è¯
    config = _config or load_config()
    keywords = config.get("alerts", {}).get("keywords", [])
    for msg in messages:
        text = (msg.get("text") or "").lower()
        msg["alert_keywords"] = [kw for kw in keywords if kw.lower() in text]

    return {"data": messages}


@app.get("/api/export")
async def api_export(
    hours: int = Query(default=24),
    group_id: Optional[int] = Query(default=None),
    # D4 ä¿®å¤ï¼šåŠ æ¡æ•°ä¸Šé™å‚æ•°ï¼Œé˜²æ­¢å…¨é‡å¯¼å‡º OOM æˆ–è¶…æ—¶
    max_rows: int = Query(default=10000, le=50000, description="æœ€å¤šå¯¼å‡ºæ¡æ•°"),
    db: Database = Depends(get_db)
):
    """CSV æ•°æ®å¯¼å‡º"""
    now = datetime.now(timezone.utc)
    since = (now - timedelta(hours=hours)).isoformat(timespec='seconds')
    filename = f"tg_monitor_export_{now.strftime('%Y%m%d_%H%M')}.csv"
    
    async def generate_csv():
        output = io.StringIO()
        writer = csv.writer(output)
        writer.writerow(["ID", "ç¾¤ç»„", "å‘é€è€…", "å†…å®¹", "æ—¶é—´", "åª’ä½“ç±»å‹", "è½¬å‘"])
        yield output.getvalue()
        output.truncate(0)
        output.seek(0)
        
        chunk_size = 500
        total_fetched = 0
        while total_fetched < max_rows:
            fetch_limit = min(chunk_size, max_rows - total_fetched)
            chunk = await db.export_messages(since=since, group_id=group_id, limit=fetch_limit, offset=total_fetched)
            if not chunk:
                break
                
            for r in chunk:
                writer.writerow([
                    r["id"], r.get("group_title", ""), r.get("sender_name", ""),
                    (r.get("text") or "")[:500], r.get("date", ""),
                    r.get("media_type", ""), r.get("forward_from", ""),
                ])
            yield output.getvalue()
            output.truncate(0)
            output.seek(0)
            total_fetched += len(chunk)

    return StreamingResponse(

        generate_csv(),
        media_type="text/csv",
        headers={"Content-Disposition": f"attachment; filename={filename}"},
    )


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# æ‘˜è¦ç›¸å…³ API
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

import asyncio
import uuid
import httpx
from .summarizer import Summarizer


@app.get("/api/llm/status")
async def api_llm_status(db: Database = Depends(get_db)):
    """æ£€æµ‹ LLM ä»£ç†è¿æ¥çŠ¶æ€"""
    config = _config or load_config()
    ai_cfg = config.get("ai", {})
    api_url = ai_cfg.get("api_url", "")
    model = ai_cfg.get("model", "?")

    if not api_url:
        return {"ok": False, "error": "æœªé…ç½® ai.api_url", "url": "", "model": model}

    # å°è¯•è¯·æ±‚ /v1/models ç«¯ç‚¹æ£€æµ‹è¿é€šæ€§
    base_url = api_url.rsplit("/v1/", 1)[0] if "/v1/" in api_url else api_url.rsplit("/", 1)[0]
    test_url = f"{base_url}/v1/models"

    try:
        api_key = ai_cfg.get("api_key", "")
        headers = {}
        if api_key:
            headers["Authorization"] = f"Bearer {api_key}"
        async with httpx.AsyncClient(timeout=8) as client:
            resp = await client.get(test_url, headers=headers)
            if resp.status_code == 200:
                return {"ok": True, "url": api_url, "model": model, "test_url": test_url}
            else:
                return {"ok": False, "error": f"HTTP {resp.status_code}", "url": api_url, "model": model}
    except httpx.ConnectError:
        return {"ok": False, "error": "è¿æ¥è¢«æ‹’ç»ï¼ˆä»£ç†æœªè¿è¡Œï¼‰", "url": api_url, "model": model}
    except httpx.TimeoutException:
        return {"ok": False, "error": "è¿æ¥è¶…æ—¶", "url": api_url, "model": model}
    except Exception as e:
        return {"ok": False, "error": str(e)[:200], "url": api_url, "model": model}


@app.post("/api/summary/generate")
async def api_summary_generate(
    hours: int = Query(default=24, ge=1, le=720),
    mode: str = Query(default="quick", regex="^(quick|per_group)$"),
    db: Database = Depends(get_db)
):
    """è§¦å‘æ‘˜è¦ç”Ÿæˆï¼ˆå¼‚æ­¥ä»»åŠ¡ï¼Œè¿”å› task_id ç”¨äºè½®è¯¢è¿›åº¦ï¼‰"""
    config = _config or load_config()

    task_id = str(uuid.uuid4())[:12]
    
    # å°†ä»»åŠ¡å­˜å…¥æ•°æ®åº“
    await db.create_summary_job(task_id, group_id=None, hours=hours, mode=mode)

    async def _run_summary():
        try:
            summarizer = Summarizer(config, db)
            
            async def progress_cb(text, current, total):
                # å°†è¿›åº¦ç™¾åˆ†æ¯”æŠ˜ç®—ä¸º 0~100 çš„æ•´æ•°
                progress_pct = int((current / max(total, 1)) * 100)
                await db.update_summary_job(
                    task_id,
                    progress=progress_pct,
                    progress_text=f"{text} ({current}/{total})"
                )
                logger.info(f"Task {task_id} Progress: {text} ({current}/{total})")

            if mode == "per_group":
                result = await summarizer.summarize_per_group(hours=hours, save=True, progress_cb=progress_cb)
            else:
                result = await summarizer.summarize(hours=hours, save=True, progress_cb=progress_cb)

            if result and not result.startswith("âŒ"):
                await db.update_summary_job(task_id, status="done", result=result, progress=100)
            else:
                error_msg = result or "LLM è¿”å›ç©ºç»“æœï¼Œè¯·æ£€æŸ¥ AI ä»£ç†æ˜¯å¦åœ¨çº¿"
                await db.update_summary_job(task_id, status="error", error_msg=error_msg)

        except Exception as e:
            logger.error(f"æ‘˜è¦ç”Ÿæˆå¤±è´¥: {e}", exc_info=True)
            await db.update_summary_job(task_id, status="error", error_msg=f"{type(e).__name__}: {str(e)[:300]}")

    asyncio.create_task(_run_summary())
    return {"task_id": task_id, "status": "running"}


@app.get("/api/summary/status/{task_id}")
async def api_summary_status(task_id: str, db: Database = Depends(get_db)):
    """æŸ¥è¯¢æ‘˜è¦ç”Ÿæˆä»»åŠ¡çŠ¶æ€"""
    task = await db.get_summary_job(task_id)
    if not task:
        return {"status": "not_found", "error": "ä»»åŠ¡ä¸å­˜åœ¨"}
    
    # è½¬æ¢ä¸ºå‰ç«¯æœŸå¾…çš„æ ¼å¼ä»¥ä¿æŒå…¼å®¹æ€§
    return {
        "status": task["status"],
        "progress": task["progress_text"] or "",
        "current_step": task["progress"],  # å‰ç«¯ç”¨ current_step/total_steps ç®—ç™¾åˆ†æ¯”
        "total_steps": 100,               # é…åˆ progress=0-100 ä½¿ç”¨
        "result": task["result"],
        "error": task["error_msg"],
    }



@app.get("/api/summary/history")
async def api_summary_history(limit: int = Query(default=10, le=50), db: Database = Depends(get_db)):
    """è·å–å†å²æ‘˜è¦"""
    summaries = await db.get_latest_summaries(limit=limit)
    return {"data": summaries}


def run_dashboard(config_path=None, host="0.0.0.0", port=8501):
    """å¯åŠ¨ Dashboard"""
    import uvicorn
    logging.basicConfig(
        level=logging.INFO,
        format="%(asctime)s [%(name)s] %(levelname)s: %(message)s",
        datefmt="%H:%M:%S",
    )
    uvicorn.run("src.dashboard:app", host=host, port=port, reload=False)


if __name__ == "__main__":
    run_dashboard()
