"""
Web Dashboard V2 â€” FastAPI åç«¯
æä¾› REST API ä¾›å‰ç«¯å±•ç¤ºç›‘æ§æ•°æ®
"""
from __future__ import annotations

import asyncio
import csv
import io
import logging
from datetime import datetime, timezone, timedelta
from pathlib import Path
from typing import Optional, Dict, Any

from fastapi import FastAPI, Query, Depends, HTTPException, Body
from fastapi.staticfiles import StaticFiles
from fastapi.responses import HTMLResponse, FileResponse, StreamingResponse
from pydantic import BaseModel

from .config import load_config
from .database import Database
from .rag import RAGEngine

logger = logging.getLogger("tg-monitor.web")

app = FastAPI(title="TG Monitor Dashboard", version="2.0.0")

# å…¨å±€çŠ¶æ€
_db: Optional[Database] = None
_config: Optional[dict] = None
_rag: Optional[RAGEngine] = None

# å¤šç§Ÿæˆ·ç™»å½•æµç¨‹çš„ä¸´æ—¶ Telethon å®¢æˆ·ç«¯ç¼“å­˜ {phone -> client}
_pending_logins: Dict[str, Any] = {}


# â”€â”€â”€ Pydantic æ¨¡å‹ â”€â”€â”€
class AddTenantRequest(BaseModel):
    phone: str
    api_id: int = 0
    api_hash: str = ""


class ConfirmLoginRequest(BaseModel):
    phone: str
    code: str
    phone_code_hash: str

STATIC_DIR = Path(__file__).parent / "web" / "static"


async def get_db() -> Database:
    global _db, _config, _rag
    if _db is None:
        _config = load_config()
        _db = Database(_config["database"]["path"])
        await _db.connect()
        _rag = RAGEngine()
    return _db


@app.on_event("startup")
async def startup():
    await get_db()
    logger.info("ğŸŒ Dashboard V2 API å·²å¯åŠ¨")


@app.on_event("shutdown")
async def shutdown():
    if _db:
        await _db.close()


# â”€â”€â”€ é™æ€æ–‡ä»¶ & é¦–é¡µ â”€â”€â”€
# æŒ‚è½½ /static ï¼ˆå…¼å®¹æ—§è·¯å¾„ï¼‰
app.mount("/static", StaticFiles(directory=str(STATIC_DIR)), name="static")
# æŒ‚è½½ /assets ï¼ˆVite build è¾“å‡ºçš„ JS/CSS èµ„æºè·¯å¾„ï¼‰
ASSETS_DIR = STATIC_DIR / "assets"
if ASSETS_DIR.exists():
    app.mount("/assets", StaticFiles(directory=str(ASSETS_DIR)), name="assets")


@app.get("/", response_class=HTMLResponse)
async def index():
    return FileResponse(STATIC_DIR / "index.html")


# NOTE: SPA fallback is registered at the BOTTOM of this file so it does not shadow API routes.


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# API ç«¯ç‚¹
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

@app.get("/api/health")
async def api_health(db: Database = Depends(get_db)):
    """å¥åº·æ£€æŸ¥ (å¢å¼ºç‰ˆ)"""
    try:
        total = await db.get_message_count()
        groups = await db.get_groups()
        
        # è·å–æ•°æ®åº“æ–‡ä»¶å¤§å°
        db_path = Path(_config["database"]["path"]) if _config else Path("data/tg_monitor.db")
        db_size_mb = round(db_path.stat().st_size / (1024 * 1024), 2) if db_path.exists() else 0
        
        # è·å–æœ€æ–°çš„æ¶ˆæ¯æ—¶é—´
        recent = await db.get_recent_messages(limit=1)
        last_sync = recent[0]["date"] if recent else "never"
        
        return {
            "status": "ok", 
            "messages": total, 
            "groups": len(groups),
            "db_size_mb": db_size_mb,
            "last_sync": last_sync,
            "version": "2.0.1"
        }
    except Exception as e:
        logger.error(f"Health check failed: {e}")
        return {"status": "error", "detail": str(e)}


@app.get("/api/overview")
async def api_overview(db: Database = Depends(get_db)):
    """æ€»è§ˆæ•°æ®"""
    now = datetime.now(timezone.utc)

    total = await db.get_message_count()
    h1 = await db.get_message_count(since=(now - timedelta(hours=1)).isoformat(timespec='seconds'))
    h24 = await db.get_message_count(since=(now - timedelta(hours=24)).isoformat(timespec='seconds'))
    h7d = await db.get_message_count(since=(now - timedelta(days=7)).isoformat(timespec='seconds'))
    groups = await db.get_groups()

    # é“¾æ¥å’Œæ‘˜è¦ç»Ÿè®¡
    links = await db.get_links(limit=1)
    summaries = await db.get_latest_summaries(limit=1)

    return {
        "total_messages": total,
        "last_1h": h1,
        "last_24h": h24,
        "last_7d": h7d,
        "group_count": len(groups),
        "model": _config.get("ai", {}).get("model", "?") if _config else "?",
        "alerts_enabled": _config.get("alerts", {}).get("enabled", False) if _config else False,
    }


@app.get("/api/trends")
async def api_trends(hours: int = Query(default=72, ge=1, le=720), db: Database = Depends(get_db)):
    """æ¶ˆæ¯è¶‹åŠ¿æ•°æ®"""
    rows = await db.get_message_trends(hours=hours)
    return {"data": [{"hour": r["hour"], "count": r["count"]} for r in rows]}


@app.get("/api/comparison")
async def api_comparison(db: Database = Depends(get_db)):
    """ä»Šå¤© vs æ˜¨å¤©æ¶ˆæ¯é‡å¯¹æ¯”"""
    return await db.get_hourly_comparison()


@app.get("/api/heatmap")
async def api_heatmap(days: int = Query(default=30), db: Database = Depends(get_db)):
    """æ´»è·ƒåº¦çƒ­åŠ›å›¾æ•°æ®"""
    data = await db.get_heatmap_data(days=days)
    return {"data": data}


@app.get("/api/groups")
async def api_groups(hours: int = Query(default=24), db: Database = Depends(get_db)):
    """ç¾¤ç»„ç»Ÿè®¡"""
    now = datetime.now(timezone.utc)
    since = (now - timedelta(hours=hours)).isoformat(timespec='seconds')
    stats = await db.get_stats(since=since)
    return {"data": stats}


@app.get("/api/groups/{group_id}")
async def api_group_detail(group_id: int, hours: int = Query(default=24), db: Database = Depends(get_db)):
    """ç¾¤ç»„è¯¦æƒ… â€” æ¶ˆæ¯åˆ—è¡¨"""
    messages = await db.get_group_messages(group_id, hours=hours, limit=200)
    trends = await db.get_group_trends(group_id, hours=max(hours, 72))

    # ç¾¤ç»„åŸºæœ¬ä¿¡æ¯
    groups = await db.get_groups()
    group_info = next((g for g in groups if g["id"] == group_id), {})

    # æ´»è·ƒç”¨æˆ·
    now = datetime.now(timezone.utc)
    since = (now - timedelta(hours=hours)).isoformat(timespec='seconds')
    top = await db.get_top_senders(group_id=group_id, since=since, limit=5)

    return {
        "info": group_info,
        "messages": messages,
        "trends": trends,
        "top_senders": top,
    }


@app.get("/api/top_senders")
async def api_top_senders(hours: int = Query(default=24), limit: int = Query(default=10), db: Database = Depends(get_db)):
    """æœ€æ´»è·ƒç”¨æˆ·"""
    now = datetime.now(timezone.utc)
    since = (now - timedelta(hours=hours)).isoformat(timespec='seconds')
    top = await db.get_top_senders(since=since, limit=limit)
    return {"data": top}


@app.get("/api/links")
async def api_links(limit: int = Query(default=30), db: Database = Depends(get_db)):
    """æœ€æ–°é“¾æ¥"""
    config = _config or load_config()
    
    # åŠ¨æ€åŠ è½½è¿‡æ»¤åŸŸåï¼Œé»˜è®¤è¿‡æ»¤å†…éƒ¨çŸ­é“¾æ¥
    block_domains = config.get("filtering", {}).get(
        "block_domains", 
        ["t.me", "telegram.me", "telegram.org", "telegra.ph", "telegram.dog"]
    )
    
    links = await db.get_links_aggregated(limit=limit, block_domains=block_domains)
    return {"data": links}


@app.get("/api/search")
async def api_search(q: str = Query(..., min_length=1), limit: int = Query(default=50), db: Database = Depends(get_db)):
    """æœç´¢æ¶ˆæ¯"""
    results = await db.search_messages(q, limit=limit)
    return {"data": results, "total": len(results)}


# è¿è¡Œæ—¶å‘Šè­¦å¼€å…³è¦†ç›–ï¼ˆä¸éœ€é‡å¯ï¼Œä¼˜å…ˆçº§é«˜äº config.yamlï¼‰
_alerts_enabled_override: Optional[bool] = None


@app.get("/api/alerts_config")
@app.get("/api/alerts/config")
async def api_alerts_config(db: Database = Depends(get_db)):
    """è·å–å½“å‰å‘Šè­¦é…ç½®ï¼ˆä¼˜å…ˆè¯»æ•°æ®åº“æŒä¹…åŒ–å¼€å…³ï¼‰"""
    config = _config or load_config()
    alerts_cfg = config.get("alerts", {})
    # ä»æ•°æ®åº“è¯»è¿è¡Œæ—¶å¼€å…³ï¼›è‹¥æœªè®¾ç½®åˆ™å›è½åˆ° config.yaml
    db_enabled = await db.get_setting("alerts_enabled")
    if db_enabled is not None:
        enabled = db_enabled.lower() == "true"
    else:
        enabled = alerts_cfg.get("enabled", False)
    return {
        "enabled": enabled,
        "keywords": alerts_cfg.get("keywords", []),
    }


@app.post("/api/alerts/toggle")
async def api_alerts_toggle(body: dict = Body(default={}), db: Database = Depends(get_db)):
    """
    è¿è¡Œæ—¶å¼€å…³å…³é”®è¯å‘Šè­¦ï¼ˆæŒä¹…åŒ–è‡³æ•°æ®åº“ï¼ŒCollector ä¸‹æ¬¡ check ç”Ÿæ•ˆï¼‰
    Body: {"enabled": true/false}
    """
    enabled = body.get("enabled")
    if enabled is None:
        raise HTTPException(status_code=400, detail="ç¼ºå°‘ enabled å­—æ®µ")
    enabled_bool = bool(enabled)
    # å†™å…¥æ•°æ®åº“ï¼Œè®© AlertManager ä¸‹æ¬¡ check_message æ—¶è¯»å–
    await db.set_setting_bool("alerts_enabled", enabled_bool)
    logger.info(f"ğŸ”” å‘Šè­¦æ¨é€å·²{'å¼€å¯' if enabled_bool else 'å…³é—­'} (æŒä¹…åŒ–è‡³ DB)")
    return {"ok": True, "enabled": enabled_bool}


@app.get("/api/settings/retention")
async def api_get_retention(db: Database = Depends(get_db)):
    """è·å–æ•°æ®ä¿ç•™ç­–ç•¥"""
    val = await db.get_setting("retention_days")
    if val is not None:
        try:
            days = int(val)
        except ValueError:
            config = _config or load_config()
            days = config.get("monitoring", {}).get("keep_days", 90)
    else:
        config = _config or load_config()
        days = config.get("monitoring", {}).get("keep_days", 90)
    return {"retention_days": days}


@app.post("/api/settings/retention")
async def api_set_retention(body: dict = Body(...), db: Database = Depends(get_db)):
    """ä¿®æ”¹æ•°æ®ä¿ç•™ç­–ç•¥"""
    days = body.get("retention_days")
    if type(days) is not int or days < 1:
        raise HTTPException(status_code=400, detail="retention_days å¿…é¡»æ˜¯å¤§äº 0 çš„æ•´æ•°")
    await db.set_setting("retention_days", str(days))
    logger.info(f"ğŸ’¾ æ•°æ®ä¿ç•™ç­–ç•¥å·²æ›´æ–°ä¸º {days} å¤©")
    return {"ok": True, "retention_days": days}


@app.get("/api/recent_messages")
async def api_recent_messages(
    limit: int = Query(default=100, le=500),
    group_id: Optional[int] = Query(default=None),
    db: Database = Depends(get_db)
):
    """æœ€æ–°æ¶ˆæ¯æµï¼ˆå§‹ç»ˆè¿”å›æœ€æ–°çš„ N æ¡ï¼‰"""
    messages = await db.get_recent_messages(limit=limit, group_id=group_id)

    groups = await db.get_groups()
    group_map = {g["id"]: g["title"] for g in groups}
    for msg in messages:
        msg["group_title"] = group_map.get(msg.get("group_id", 0), "æœªçŸ¥")

    # æ£€æŸ¥æ˜¯å¦å‘½ä¸­å‘Šè­¦å…³é”®è¯
    config = _config or load_config()
    keywords = config.get("alerts", {}).get("keywords", [])
    for msg in messages:
        text = (msg.get("text") or "").lower()
        msg["alert_keywords"] = [kw for kw in keywords if kw.lower() in text]

    return {"data": messages}


@app.get("/api/export")
async def api_export(
    hours: int = Query(default=24),
    group_id: Optional[int] = Query(default=None),
    # D4 ä¿®å¤ï¼šåŠ æ¡æ•°ä¸Šé™å‚æ•°ï¼Œé˜²æ­¢å…¨é‡å¯¼å‡º OOM æˆ–è¶…æ—¶
    max_rows: int = Query(default=10000, le=50000, description="æœ€å¤šå¯¼å‡ºæ¡æ•°"),
    db: Database = Depends(get_db)
):
    """CSV æ•°æ®å¯¼å‡º"""
    now = datetime.now(timezone.utc)
    since = (now - timedelta(hours=hours)).isoformat(timespec='seconds')
    filename = f"tg_monitor_export_{now.strftime('%Y%m%d_%H%M')}.csv"
    
    async def generate_csv():
        output = io.StringIO()
        writer = csv.writer(output)
        writer.writerow(["ID", "ç¾¤ç»„", "å‘é€è€…", "å†…å®¹", "æ—¶é—´", "åª’ä½“ç±»å‹", "è½¬å‘"])
        yield output.getvalue()
        output.truncate(0)
        output.seek(0)
        
        chunk_size = 500
        total_fetched = 0
        while total_fetched < max_rows:
            fetch_limit = min(chunk_size, max_rows - total_fetched)
            chunk = await db.export_messages(since=since, group_id=group_id, limit=fetch_limit, offset=total_fetched)
            if not chunk:
                break
                
            for r in chunk:
                writer.writerow([
                    r["id"], r.get("group_title", ""), r.get("sender_name", ""),
                    (r.get("text") or "")[:500], r.get("date", ""),
                    r.get("media_type", ""), r.get("forward_from", ""),
                ])
            yield output.getvalue()
            output.truncate(0)
            output.seek(0)
            total_fetched += len(chunk)

    return StreamingResponse(

        generate_csv(),
        media_type="text/csv",
        headers={"Content-Disposition": f"attachment; filename={filename}"},
    )


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# RAG Chat API
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

from pydantic import BaseModel
import httpx

class AskRequest(BaseModel):
    query: str
    
@app.post("/api/chat/ask")
async def api_chat_ask(req: AskRequest, db: Database = Depends(get_db)):
    """åŸºäºæœ¬åœ°é‡åŒ–åº“çš„ RAG æ™ºèƒ½é—®ç­”æ¥å£"""
    if not _rag or not _rag._enabled:
        return {"answer": "ç”±äº ChromaDB ç¼ºå°‘ï¼ŒRAG å‘é‡åº“æœªå¼€å¯ã€‚è¯·æ£€æŸ¥æ˜¯å¦å®‰è£…äº† chromadbï¼Œå¹¶é‡æ–°å¯åŠ¨åº”ç”¨ã€‚", "citations": []}
        
    query = req.query
    if not query:
        return {"answer": "è¯·è¾“å…¥é—®é¢˜", "citations": []}
        
    results = _rag.search(query, n_results=15)
    
    if not results:
        return {"answer": "åœ¨è¿‡å»æ”¶å½•çš„ç¾¤èŠæ¶ˆæ¯ä¸­ï¼Œæœªèƒ½æ£€ç´¢åˆ°ç›¸å…³çš„ä¸Šä¸‹æ–‡ç‰‡æ®µã€‚æ¢ä¸ªæé—®æ–¹å¼è¯•è¯•ï¼Ÿ", "citations": []}
        
    context_parts = []
    citations = []
    for i, res in enumerate(results):
        meta = res["metadata"]
        txt = res["content"]
        # ç»™æ¨¡å‹å–‚å¸¦ç¼–å·çš„ä¸Šä¸‹æ–‡
        context_parts.append(f"[{i+1}] {txt}")
        citations.append({
            "id": i+1,
            "group_id": meta.get("group_id"),
            "sender_name": meta.get("sender_name"),
            "date": meta.get("date"),
            "text": txt
        })
        
    context_str = "\n\n".join(context_parts)
    
    config = _config or load_config()
    ai_cfg = config.get("ai", {})
    api_url = ai_cfg.get("api_url", "http://localhost:18789/v1/chat/completions")
    api_key = ai_cfg.get("api_key", "")
    model = ai_cfg.get("model", "gpt-4o")
    
    system_prompt = (
        "ä½ æ˜¯ä¸€ä¸ªèªæ˜ã€ä¸­ç«‹ä¸”ä¸“ä¸šçš„ TG èŠå¤©è®°å½•åˆ†ææ™ºå›Šã€‚\n"
        "æˆ‘ä¼šæä¾›ç›¸å…³çš„æœç´¢ç‰‡æ®µç»™ä½ ï¼ˆå¦‚ä¸‹ï¼‰ï¼Œè¯·åŸºäºç‰‡æ®µå›ç­”ç”¨æˆ·çš„é—®é¢˜ã€‚\n"
        "éå¸¸é‡è¦ï¼šå¦‚æœç‰‡æ®µä¸­æ²¡æœ‰ä¸é—®é¢˜ç›¸å…³çš„ä¿¡æ¯ï¼Œè¯·ç›´æ¥å›ç­”â€œè®°å½•ä¸­æœªæœç´¢åˆ°ç›¸å…³ä¿¡æ¯â€ï¼Œç»å¯¹ä¸è¦ç¼–é€ æˆ–åŸºäºé€šç”¨çŸ¥è¯†ç¡¬ç­”ã€‚\n"
        "éå¸¸é‡è¦ï¼šä½ çš„å›ç­”**å¿…é¡»**ä½¿ç”¨æ•°å­—æ ‡è®°è¿›è¡Œæº¯æºå¼•ç”¨ï¼Œå¦‚ï¼š'æ ¹æ®[1]çš„è¯´æ˜...ï¼Œå¹¶ä¸”[3]ä¹Ÿæåˆ°äº†...'\n\n"
        "ã€æœç´¢ç‰‡æ®µä¸Šä¸‹æ–‡ã€‘\n"
        f"{context_str}"
    )
    
    payload = {
        "model": model,
        "messages": [
            {"role": "system", "content": system_prompt},
            {"role": "user", "content": query}
        ],
        "temperature": 0.2, # é—®ç­”é€šå¸¸é™ä½å¹»è§‰
    }
    
    headers = {"Content-Type": "application/json"}
    if api_key:
        headers["Authorization"] = f"Bearer {api_key}"
        
    try:
        async with httpx.AsyncClient(timeout=30.0) as client:
            resp = await client.post(api_url, json=payload, headers=headers)
            resp.raise_for_status()
            reply = resp.json()["choices"][0]["message"]["content"]
            
            return {
                "answer": reply,
                "citations": citations
            }
    except Exception as e:
        logger.error(f"RAG Chat AI è¯·æ±‚å¤±è´¥: {e}")
        return {"answer": f"ç”±äº AI æ¥å£å¼‚å¸¸æ— æ³•ç”Ÿæˆå›ç­”: {str(e)[:100]}", "citations": citations}


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# æ‘˜è¦ç›¸å…³ API
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

import asyncio
import uuid
import httpx
from .summarizer import Summarizer


@app.get("/api/llm/status")
async def api_llm_status(db: Database = Depends(get_db)):
    """æ£€æµ‹ LLM ä»£ç†è¿æ¥çŠ¶æ€"""
    config = _config or load_config()
    ai_cfg = config.get("ai", {})
    api_url = ai_cfg.get("api_url", "")
    model = ai_cfg.get("model", "?")

    if not api_url:
        return {"ok": False, "error": "æœªé…ç½® ai.api_url", "url": "", "model": model}

    # å°è¯•è¯·æ±‚ /v1/models ç«¯ç‚¹æ£€æµ‹è¿é€šæ€§
    base_url = api_url.rsplit("/v1/", 1)[0] if "/v1/" in api_url else api_url.rsplit("/", 1)[0]
    test_url = f"{base_url}/v1/models"

    try:
        api_key = ai_cfg.get("api_key", "")
        headers = {}
        if api_key:
            headers["Authorization"] = f"Bearer {api_key}"
        async with httpx.AsyncClient(timeout=8) as client:
            resp = await client.get(test_url, headers=headers)
            if resp.status_code == 200:
                return {"ok": True, "url": api_url, "model": model, "test_url": test_url}
            else:
                return {"ok": False, "error": f"HTTP {resp.status_code}", "url": api_url, "model": model}
    except httpx.ConnectError:
        return {"ok": False, "error": "è¿æ¥è¢«æ‹’ç»ï¼ˆä»£ç†æœªè¿è¡Œï¼‰", "url": api_url, "model": model}
    except httpx.TimeoutException:
        return {"ok": False, "error": "è¿æ¥è¶…æ—¶", "url": api_url, "model": model}
    except Exception as e:
        return {"ok": False, "error": str(e)[:200], "url": api_url, "model": model}


@app.post("/api/summary/generate")
async def api_summary_generate(
    hours: int = Query(default=24, ge=1, le=720),
    mode: str = Query(default="quick", regex="^(quick|per_group)$"),
    db: Database = Depends(get_db)
):
    """è§¦å‘æ‘˜è¦ç”Ÿæˆï¼ˆå¼‚æ­¥ä»»åŠ¡ï¼Œè¿”å› task_id ç”¨äºè½®è¯¢è¿›åº¦ï¼‰"""
    config = _config or load_config()

    task_id = str(uuid.uuid4())[:12]
    
    # å°†ä»»åŠ¡å­˜å…¥æ•°æ®åº“
    await db.create_summary_job(task_id, group_id=None, hours=hours, mode=mode)

    async def _run_summary():
        try:
            summarizer = Summarizer(config, db)
            
            async def progress_cb(text, current, total):
                # å°†è¿›åº¦ç™¾åˆ†æ¯”æŠ˜ç®—ä¸º 0~100 çš„æ•´æ•°
                progress_pct = int((current / max(total, 1)) * 100)
                await db.update_summary_job(
                    task_id,
                    progress=progress_pct,
                    progress_text=f"{text} ({current}/{total})"
                )
                logger.info(f"Task {task_id} Progress: {text} ({current}/{total})")

            if mode == "per_group":
                result = await summarizer.summarize_per_group(hours=hours, save=True, progress_cb=progress_cb)
            else:
                result = await summarizer.summarize(hours=hours, save=True, progress_cb=progress_cb)

            if result and not result.startswith("âŒ"):
                await db.update_summary_job(task_id, status="done", result=result, progress=100)
            else:
                error_msg = result or "LLM è¿”å›ç©ºç»“æœï¼Œè¯·æ£€æŸ¥ AI ä»£ç†æ˜¯å¦åœ¨çº¿"
                await db.update_summary_job(task_id, status="error", error_msg=error_msg)

        except Exception as e:
            logger.error(f"æ‘˜è¦ç”Ÿæˆå¤±è´¥: {e}", exc_info=True)
            await db.update_summary_job(task_id, status="error", error_msg=f"{type(e).__name__}: {str(e)[:300]}")

    asyncio.create_task(_run_summary())
    return {"task_id": task_id, "status": "running"}


@app.get("/api/summary/status/{task_id}")
async def api_summary_status(task_id: str, db: Database = Depends(get_db)):
    """æŸ¥è¯¢æ‘˜è¦ç”Ÿæˆä»»åŠ¡çŠ¶æ€"""
    task = await db.get_summary_job(task_id)
    if not task:
        return {"status": "not_found", "error": "ä»»åŠ¡ä¸å­˜åœ¨"}
    
    # è½¬æ¢ä¸ºå‰ç«¯æœŸå¾…çš„æ ¼å¼ä»¥ä¿æŒå…¼å®¹æ€§
    return {
        "status": task["status"],
        "progress": task["progress_text"] or "",
        "current_step": task["progress"],  # å‰ç«¯ç”¨ current_step/total_steps ç®—ç™¾åˆ†æ¯”
        "total_steps": 100,               # é…åˆ progress=0-100 ä½¿ç”¨
        "result": task["result"],
        "error": task["error_msg"],
    }



@app.get("/api/summary/history")
async def api_summary_history(limit: int = Query(default=10, le=50), db: Database = Depends(get_db)):
    """è·å–å†å²æ‘˜è¦"""
    summaries = await db.get_latest_summaries(limit=limit)
    return {"data": summaries}



# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# Phase 4: ç¤¾äº¤å…³ç³»å›¾è°±ä¸ KOL æŒ–æ˜ API
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

@app.get("/api/graph/nodes")
async def api_graph_nodes(
    group_id: Optional[int] = Query(default=None, description="æŒ‡å®šç¾¤ç»„ IDï¼Œä¸å¡«åˆ™è·¨ç¾¤å…¨å±€"),
    days: int = Query(default=30, ge=1, le=180),
    limit: int = Query(default=60, le=200),
    db: Database = Depends(get_db)
):
    """
    KOL èŠ‚ç‚¹æ•°æ® â€” æ¯ä¸ªèŠ‚ç‚¹ä»£è¡¨ä¸€ä¸ªç”¨æˆ·
    è¿”å›: id, name, msg_count, reply_received, forward_received, kol_score, groups
    """
    conn = db._core.conn
    since = (datetime.now(timezone.utc) - timedelta(days=days)).isoformat(timespec='seconds')

    group_filter = "AND m.group_id = :gid" if group_id else ""
    params: dict = {"since": since, "limit": limit}
    if group_id:
        params["gid"] = group_id

    # 1. åŸºç¡€å‘è¨€é‡
    rows = await conn.execute_fetchall(f"""
        SELECT
            m.sender_id,
            m.sender_name,
            COUNT(*)                          AS msg_count,
            GROUP_CONCAT(DISTINCT g.title)    AS groups
        FROM messages m
        LEFT JOIN groups g ON g.id = m.group_id
        WHERE m.sender_id IS NOT NULL
          AND m.sender_name IS NOT NULL
          AND m.date >= :since
          {group_filter}
        GROUP BY m.sender_id
        ORDER BY msg_count DESC
        LIMIT :limit
    """, params)

    if not rows:
        return {"nodes": []}

    # 2. è¢«å›å¤æ¬¡æ•°ï¼ˆå…¶ä»–äºº reply_to äº†è¿™ä¸ªäººçš„æ¶ˆæ¯ï¼‰
    top_ids = [r["sender_id"] for r in rows]
    placeholders = ",".join("?" * len(top_ids))

    replied_map: dict = {}
    try:
        replied_rows = await conn.execute_fetchall(f"""
            SELECT target.sender_id, COUNT(*) AS reply_count
            FROM messages replier
            JOIN messages target ON target.id = replier.reply_to_id
                                AND target.group_id = replier.group_id
            WHERE replier.reply_to_id IS NOT NULL
              AND replier.date >= ?
              AND target.sender_id IN ({placeholders})
            GROUP BY target.sender_id
        """, [since] + top_ids)
        replied_map = {r["sender_id"]: r["reply_count"] for r in replied_rows}
    except Exception:
        pass

    # 3. è¢«è½¬å‘æ¬¡æ•°ï¼ˆforward_from å­—æ®µåŒ…å«åå­—ï¼‰
    fwd_map: dict = {}
    try:
        fwd_rows = await conn.execute_fetchall(f"""
            SELECT forward_from, COUNT(*) AS fwd_count
            FROM messages
            WHERE forward_from IS NOT NULL
              AND date >= ?
              {group_filter}
            GROUP BY forward_from
        """, [since] + ([group_id] if group_id else []))
        fwd_map = {r["forward_from"]: r["fwd_count"] for r in fwd_rows}
    except Exception:
        pass

    # 4. åˆå¹¶è®¡ç®— KOL ç»¼åˆå¾—åˆ†
    nodes = []
    for r in rows:
        sid = r["sender_id"]
        name = r["sender_name"] or f"User#{sid}"
        msg_count = r["msg_count"]
        reply_recv = replied_map.get(sid, 0)
        fwd_recv = fwd_map.get(name, 0)
        # æƒé‡: å‘è¨€æƒé‡ä½ï¼Œè¢«å›å¤/è½¬å‘æƒé‡é«˜ï¼ˆä»£è¡¨çœŸå½±å“åŠ›ï¼‰
        kol_score = round(msg_count * 1.0 + reply_recv * 3.0 + fwd_recv * 2.0, 1)
        nodes.append({
            "id": sid,
            "name": name,
            "msg_count": msg_count,
            "reply_received": reply_recv,
            "forward_received": fwd_recv,
            "kol_score": kol_score,
            "groups": r["groups"] or "",
        })

    nodes.sort(key=lambda x: x["kol_score"], reverse=True)
    return {"nodes": nodes, "total": len(nodes)}


@app.get("/api/graph/edges")
async def api_graph_edges(
    group_id: Optional[int] = Query(default=None),
    days: int = Query(default=30, ge=1, le=180),
    min_weight: int = Query(default=2, description="æœ€å°‘äº’åŠ¨æ¬¡æ•°æ‰å»ºè¾¹"),
    db: Database = Depends(get_db)
):
    """
    äº’åŠ¨å…³ç³»è¾¹æ•°æ®ï¼ˆæœ‰å‘åŠ æƒå›¾ï¼‰
    æ¯æ¡è¾¹: source(sender), target(è¢«å›å¤è€…), weight(å›å¤æ¬¡æ•°)
    """
    conn = db._core.conn
    since = (datetime.now(timezone.utc) - timedelta(days=days)).isoformat(timespec='seconds')
    group_filter = "AND replier.group_id = ?" if group_id else ""
    params = [since, min_weight] + ([group_id] if group_id else [])

    try:
        rows = await conn.execute_fetchall(f"""
            SELECT
                replier.sender_id   AS source_id,
                replier.sender_name AS source_name,
                target.sender_id    AS target_id,
                target.sender_name  AS target_name,
                COUNT(*)            AS weight
            FROM messages replier
            JOIN messages target ON target.id = replier.reply_to_id
                                AND target.group_id = replier.group_id
            WHERE replier.reply_to_id IS NOT NULL
              AND replier.sender_id IS NOT NULL
              AND target.sender_id IS NOT NULL
              AND replier.sender_id != target.sender_id
              AND replier.date >= ?
              {group_filter}
            GROUP BY replier.sender_id, target.sender_id
            HAVING COUNT(*) >= ?
            ORDER BY weight DESC
            LIMIT 300
        """, params)
    except Exception as e:
        logger.warning(f"graph/edges query failed: {e}")
        return {"edges": []}

    edges = [{
        "source": r["source_id"],
        "source_name": r["source_name"],
        "target": r["target_id"],
        "target_name": r["target_name"],
        "weight": r["weight"],
    } for r in rows]

    return {"edges": edges}


@app.get("/api/graph/heatmap")
async def api_graph_heatmap(
    group_id: Optional[int] = Query(default=None),
    days: int = Query(default=60, ge=7, le=365),
    db: Database = Depends(get_db)
):
    """
    æ´»è·ƒæ—¶åŒºçƒ­åŠ›çŸ©é˜µ 7Ã—24 â€” (weekday, hour) â†’ message_count
    weekday: 0=Monâ€¦6=Sun, hour: 0â€“23
    """
    conn = db._core.conn
    since = (datetime.now(timezone.utc) - timedelta(days=days)).isoformat(timespec='seconds')
    group_filter = "AND group_id = ?" if group_id else ""
    params = [since] + ([group_id] if group_id else [])

    try:
        rows = await conn.execute_fetchall(f"""
            SELECT
                CAST(strftime('%w', date) AS INTEGER)  AS weekday_sun,
                CAST(strftime('%H', date) AS INTEGER)  AS hour,
                COUNT(*)                               AS count
            FROM messages
            WHERE date >= ?
              {group_filter}
            GROUP BY weekday_sun, hour
        """, params)
    except Exception as e:
        logger.warning(f"graph/heatmap query failed: {e}")
        return {"matrix": []}

    # strftime('%w') returns 0=Sun..6=Sat, remap to 0=Mon..6=Sun
    matrix = []
    for r in rows:
        wd_sun = r["weekday_sun"]
        wd_mon = (wd_sun - 1) % 7  # 0=Mon
        matrix.append({"weekday": wd_mon, "hour": r["hour"], "count": r["count"]})

    return {"matrix": matrix, "days": days}


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# Phase 3: å¤šç§Ÿæˆ· Auth Portal API
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

@app.get("/api/tenants")
async def api_list_tenants(db: Database = Depends(get_db)):
    """åˆ—å‡ºæ‰€æœ‰ç§Ÿæˆ·è´¦å·"""
    tenants = await db.get_tenants(active_only=False)
    # è„±æ•: éšè— api_hash
    for t in tenants:
        t["api_hash"] = t["api_hash"][:6] + "****" if t.get("api_hash") else ""
    return {"data": tenants}


@app.post("/api/tenants/send_code")
async def api_send_code(body: AddTenantRequest):
    """
    å‘èµ·ç™»å½•æµç¨‹:
    1. ç”¨é…ç½®é‡Œçš„ api_id/api_hashï¼ˆæˆ– body é‡Œä¼ çš„ï¼‰
    2. åˆ›å»ºä¸´æ—¶ Telethon client -> å‘é€éªŒè¯ç åˆ°æŒ‡å®šæ‰‹æœºå·
    3. è¿”å› phone_code_hash ä¾›ä¸‹ä¸€æ­¥ç¡®è®¤
    """
    try:
        from telethon import TelegramClient
        from telethon.sessions import MemorySession

        # ä¼˜å…ˆä½¿ç”¨ body ä¼ å…¥çš„ api_id/api_hashï¼Œå¦åˆ™ä»é…ç½®è¯»å–
        cfg = _config or load_config()
        tg_cfg = cfg.get("telegram", {})
        api_id = body.api_id or int(tg_cfg.get("api_id", 0))
        api_hash = body.api_hash or tg_cfg.get("api_hash", "")

        if not api_id or not api_hash:
            raise HTTPException(status_code=400, detail="ç¼ºå°‘ api_id / api_hash")

        phone = body.phone.strip()
        session_name = f"tenant_{phone.replace('+', '').replace(' ', '')}"

        # å¦‚æœå·²æœ‰ç­‰å¾…ä¸­çš„ clientï¼Œå…ˆæ–­å¼€
        if phone in _pending_logins:
            try:
                await _pending_logins[phone]["client"].disconnect()
            except Exception:
                pass

        client = TelegramClient(MemorySession(), api_id, api_hash)
        await client.connect()
        result = await client.send_code_request(phone)

        _pending_logins[phone] = {
            "client": client,
            "phone_code_hash": result.phone_code_hash,
            "api_id": api_id,
            "api_hash": api_hash,
            "session_name": session_name,
        }

        logger.info(f"ğŸ“± éªŒè¯ç å·²å‘é€è‡³ {phone}")
        return {"ok": True, "phone_code_hash": result.phone_code_hash, "session_name": session_name}

    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"å‘é€éªŒè¯ç å¤±è´¥: {e}", exc_info=True)
        raise HTTPException(status_code=500, detail=str(e))


@app.post("/api/tenants/confirm_login")
async def api_confirm_login(body: ConfirmLoginRequest, db: Database = Depends(get_db)):
    """
    éªŒè¯ç ç¡®è®¤:
    1. ç™»å½•æˆåŠŸåå°† session å­—ç¬¦ä¸²æŒä¹…åŒ–åˆ°ç£ç›˜
    2. åœ¨ tenants è¡¨ä¿å­˜å…ƒæ•°æ®
    """
    phone = body.phone.strip()
    if phone not in _pending_logins:
        raise HTTPException(status_code=400, detail="æœªæ‰¾åˆ°ç­‰å¾…ä¸­çš„ç™»å½•è¯·æ±‚ï¼Œè¯·å…ˆè°ƒç”¨ send_code")

    pending = _pending_logins[phone]
    client = pending["client"]

    try:
        await client.sign_in(
            phone=phone,
            code=body.code,
            phone_code_hash=body.phone_code_hash or pending["phone_code_hash"],
        )
    except Exception as e:
        raise HTTPException(status_code=401, detail=f"ç™»å½•å¤±è´¥: {e}")

    me = await client.get_me()
    session_name = pending["session_name"]

    # å°† session æŒä¹…åŒ–ï¼ˆå­˜ä¸ºæ–‡ä»¶ sessionï¼‰
    from telethon.sessions import SQLiteSession
    sessions_dir = Path("data/sessions")
    sessions_dir.mkdir(parents=True, exist_ok=True)
    session_path = sessions_dir / session_name

    persistent_client = TelegramClient(
        str(session_path), pending["api_id"], pending["api_hash"]
    )
    await persistent_client.connect()
    # ä» MemorySession è¿ç§»ï¼šç›´æ¥ sign_in ä¼šç”Ÿæˆæ–°çš„ sqlite session
    try:
        await persistent_client.sign_in(
            phone=phone,
            code=body.code,
            phone_code_hash=body.phone_code_hash or pending["phone_code_hash"],
        )
    except Exception:
        pass  # å¯èƒ½å·²ç»åœ¨ client ä¸Šç™»å½•è¿‡ï¼Œå¿½ç•¥
    await persistent_client.disconnect()

    # ä¿å­˜åˆ°æ•°æ®åº“
    tenant_id = await db.add_tenant(
        api_id=pending["api_id"],
        api_hash=pending["api_hash"],
        phone=phone,
        session_name=str(session_path),
    )

    # æ¸…ç†ä¸´æ—¶ client
    await client.disconnect()
    del _pending_logins[phone]

    logger.info(f"âœ… ç§Ÿæˆ· #{tenant_id} ç™»å½•æˆåŠŸ: {me.first_name} ({phone})")
    return {
        "ok": True,
        "tenant_id": tenant_id,
        "name": me.first_name,
        "username": me.username,
        "phone": phone,
    }


@app.delete("/api/tenants/{tenant_id}")
async def api_deactivate_tenant(tenant_id: int, db: Database = Depends(get_db)):
    """åœç”¨ç§Ÿæˆ·è´¦å·"""
    await db.set_tenant_active(tenant_id, False)
    return {"ok": True, "message": f"ç§Ÿæˆ· #{tenant_id} å·²åœç”¨"}


@app.post("/api/tenants/{tenant_id}/activate")
async def api_activate_tenant(tenant_id: int, db: Database = Depends(get_db)):
    """é‡æ–°å¯ç”¨ç§Ÿæˆ·è´¦å·"""
    await db.set_tenant_active(tenant_id, True)
    return {"ok": True, "message": f"ç§Ÿæˆ· #{tenant_id} å·²å¯ç”¨"}


# â”€â”€â”€ SPA Fallback â”€â”€â”€
# å¿…é¡»æ”¾åœ¨æ‰€æœ‰ API è·¯ç”±ä¹‹åï¼Œè®©æ‰€æœ‰æœªå‘½ä¸­çš„è·¯å¾„è¿”å› index.html
@app.get("/{full_path:path}", response_class=HTMLResponse)
async def spa_fallback(full_path: str):
    """è®© React Router çš„å‰ç«¯è·¯ç”±ä¸ 404ï¼ˆSPA é€šé…å›é€€ï¼‰"""
    # assets / static / api èµ°å„è‡ªçš„æŒ‚è½½ï¼Œä¸åº”åˆ°è¿™é‡Œ
    return FileResponse(STATIC_DIR / "index.html")


def run_dashboard(config_path=None, host="0.0.0.0", port=8501):
    """å¯åŠ¨ Dashboard"""
    import uvicorn
    logging.basicConfig(
        level=logging.INFO,
        format="%(asctime)s [%(name)s] %(levelname)s: %(message)s",
        datefmt="%H:%M:%S",
    )
    uvicorn.run("src.dashboard:app", host=host, port=port, reload=False)


if __name__ == "__main__":
    run_dashboard()
