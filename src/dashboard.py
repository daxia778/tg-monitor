"""
Web Dashboard V2 â€” FastAPI åç«¯
æä¾› REST API ä¾›å‰ç«¯å±•ç¤ºç›‘æ§æ•°æ®
"""
from __future__ import annotations

import csv
import io
import logging
from datetime import datetime, timezone, timedelta
from pathlib import Path
from typing import Optional

from fastapi import FastAPI, Query
from fastapi.staticfiles import StaticFiles
from fastapi.responses import HTMLResponse, FileResponse, StreamingResponse

from .config import load_config
from .database import Database

logger = logging.getLogger("tg-monitor.web")

app = FastAPI(title="TG Monitor Dashboard", version="2.0.0")

# å…¨å±€çŠ¶æ€
_db: Optional[Database] = None
_config: Optional[dict] = None

STATIC_DIR = Path(__file__).parent / "web" / "static"


async def get_db() -> Database:
    global _db, _config
    if _db is None:
        _config = load_config()
        _db = Database(_config["database"]["path"])
        await _db.connect()
    return _db


@app.on_event("startup")
async def startup():
    await get_db()
    logger.info("ğŸŒ Dashboard V2 API å·²å¯åŠ¨")


@app.on_event("shutdown")
async def shutdown():
    if _db:
        await _db.close()


# â”€â”€â”€ é™æ€æ–‡ä»¶ & é¦–é¡µ â”€â”€â”€
app.mount("/static", StaticFiles(directory=str(STATIC_DIR)), name="static")


@app.get("/", response_class=HTMLResponse)
async def index():
    return FileResponse(STATIC_DIR / "index.html")


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# API ç«¯ç‚¹
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

@app.get("/api/health")
async def api_health():
    """å¥åº·æ£€æŸ¥ (å¢å¼ºç‰ˆ)"""
    try:
        db = await get_db()
        total = await db.get_message_count()
        groups = await db.get_groups()
        
        # è·å–æ•°æ®åº“æ–‡ä»¶å¤§å°
        db_path = Path(_config["database"]["path"]) if _config else Path("data/tg_monitor.db")
        db_size_mb = round(db_path.stat().st_size / (1024 * 1024), 2) if db_path.exists() else 0
        
        # è·å–æœ€æ–°çš„æ¶ˆæ¯æ—¶é—´
        recent = await db.get_recent_messages(limit=1)
        last_sync = recent[0]["date"] if recent else "never"
        
        return {
            "status": "ok", 
            "messages": total, 
            "groups": len(groups),
            "db_size_mb": db_size_mb,
            "last_sync": last_sync,
            "version": "2.0.1"
        }
    except Exception as e:
        logger.error(f"Health check failed: {e}")
        return {"status": "error", "detail": str(e)}


@app.get("/api/overview")
async def api_overview():
    """æ€»è§ˆæ•°æ®"""
    db = await get_db()
    now = datetime.now(timezone.utc)

    total = await db.get_message_count()
    h1 = await db.get_message_count(since=(now - timedelta(hours=1)).isoformat(timespec='seconds'))
    h24 = await db.get_message_count(since=(now - timedelta(hours=24)).isoformat(timespec='seconds'))
    h7d = await db.get_message_count(since=(now - timedelta(days=7)).isoformat(timespec='seconds'))
    groups = await db.get_groups()

    # é“¾æ¥å’Œæ‘˜è¦ç»Ÿè®¡
    links = await db.get_links(limit=1)
    summaries = await db.get_latest_summaries(limit=1)

    return {
        "total_messages": total,
        "last_1h": h1,
        "last_24h": h24,
        "last_7d": h7d,
        "group_count": len(groups),
        "model": _config.get("ai", {}).get("model", "?") if _config else "?",
        "alerts_enabled": _config.get("alerts", {}).get("enabled", False) if _config else False,
    }


@app.get("/api/trends")
async def api_trends(hours: int = Query(default=72, ge=1, le=720)):
    """æ¶ˆæ¯è¶‹åŠ¿æ•°æ®"""
    db = await get_db()
    rows = await db.get_message_trends(hours=hours)
    return {"data": [{"hour": r["hour"], "count": r["count"]} for r in rows]}


@app.get("/api/comparison")
async def api_comparison():
    """ä»Šå¤© vs æ˜¨å¤©æ¶ˆæ¯é‡å¯¹æ¯”"""
    db = await get_db()
    return await db.get_hourly_comparison()


@app.get("/api/heatmap")
async def api_heatmap(days: int = Query(default=30)):
    """æ´»è·ƒåº¦çƒ­åŠ›å›¾æ•°æ®"""
    db = await get_db()
    data = await db.get_heatmap_data(days=days)
    return {"data": data}


@app.get("/api/groups")
async def api_groups(hours: int = Query(default=24)):
    """ç¾¤ç»„ç»Ÿè®¡"""
    db = await get_db()
    now = datetime.now(timezone.utc)
    since = (now - timedelta(hours=hours)).isoformat(timespec='seconds')
    stats = await db.get_stats(since=since)
    return {"data": stats}


@app.get("/api/groups/{group_id}")
async def api_group_detail(group_id: int, hours: int = Query(default=24)):
    """ç¾¤ç»„è¯¦æƒ… â€” æ¶ˆæ¯åˆ—è¡¨"""
    db = await get_db()
    messages = await db.get_group_messages(group_id, hours=hours, limit=200)
    trends = await db.get_group_trends(group_id, hours=max(hours, 72))

    # ç¾¤ç»„åŸºæœ¬ä¿¡æ¯
    groups = await db.get_groups()
    group_info = next((g for g in groups if g["id"] == group_id), {})

    # æ´»è·ƒç”¨æˆ·
    now = datetime.now(timezone.utc)
    since = (now - timedelta(hours=hours)).isoformat(timespec='seconds')
    top = await db.get_top_senders(group_id=group_id, since=since, limit=5)

    return {
        "info": group_info,
        "messages": messages,
        "trends": trends,
        "top_senders": top,
    }


@app.get("/api/top_senders")
async def api_top_senders(hours: int = Query(default=24), limit: int = Query(default=10)):
    """æœ€æ´»è·ƒç”¨æˆ·"""
    db = await get_db()
    now = datetime.now(timezone.utc)
    since = (now - timedelta(hours=hours)).isoformat(timespec='seconds')
    top = await db.get_top_senders(since=since, limit=limit)
    return {"data": top}


@app.get("/api/links")
async def api_links(limit: int = Query(default=30)):
    """æœ€æ–°é“¾æ¥"""
    db = await get_db()
    config = _config or load_config()
    
    # åŠ¨æ€åŠ è½½è¿‡æ»¤åŸŸåï¼Œé»˜è®¤è¿‡æ»¤å†…éƒ¨çŸ­é“¾æ¥
    block_domains = config.get("filtering", {}).get(
        "block_domains", 
        ["t.me", "telegram.me", "telegram.org", "telegra.ph", "telegram.dog"]
    )
    
    links = await db.get_links(limit=limit, block_domains=block_domains)
    return {"data": links}


@app.get("/api/search")
async def api_search(q: str = Query(..., min_length=1), limit: int = Query(default=50)):
    """æœç´¢æ¶ˆæ¯"""
    db = await get_db()
    results = await db.search_messages(q, limit=limit)
    return {"data": results, "total": len(results)}


@app.get("/api/alerts_config")
async def api_alerts_config():
    """å‘Šè­¦é…ç½®"""
    config = _config or load_config()
    alerts = config.get("alerts", {})
    return {
        "enabled": alerts.get("enabled", False),
        "keywords": alerts.get("keywords", []),
    }


@app.get("/api/recent_messages")
async def api_recent_messages(
    limit: int = Query(default=100, le=500),
    group_id: Optional[int] = Query(default=None),
):
    """æœ€æ–°æ¶ˆæ¯æµï¼ˆå§‹ç»ˆè¿”å›æœ€æ–°çš„ N æ¡ï¼‰"""
    db = await get_db()
    messages = await db.get_recent_messages(limit=limit, group_id=group_id)

    groups = await db.get_groups()
    group_map = {g["id"]: g["title"] for g in groups}
    for msg in messages:
        msg["group_title"] = group_map.get(msg.get("group_id", 0), "æœªçŸ¥")

    # æ£€æŸ¥æ˜¯å¦å‘½ä¸­å‘Šè­¦å…³é”®è¯
    config = _config or load_config()
    keywords = config.get("alerts", {}).get("keywords", [])
    for msg in messages:
        text = (msg.get("text") or "").lower()
        msg["alert_keywords"] = [kw for kw in keywords if kw.lower() in text]

    return {"data": messages}


@app.get("/api/export")
async def api_export(
    hours: int = Query(default=24),
    group_id: Optional[int] = Query(default=None),
    # D4 ä¿®å¤ï¼šåŠ æ¡æ•°ä¸Šé™å‚æ•°ï¼Œé˜²æ­¢å…¨é‡å¯¼å‡º OOM æˆ–è¶…æ—¶
    max_rows: int = Query(default=10000, le=50000, description="æœ€å¤šå¯¼å‡ºæ¡æ•°"),
):
    """CSV æ•°æ®å¯¼å‡º"""
    db = await get_db()
    now = datetime.now(timezone.utc)
    since = (now - timedelta(hours=hours)).isoformat(timespec='seconds')

    rows = await db.export_messages(since=since, group_id=group_id, limit=max_rows)

    filename = f"tg_monitor_export_{now.strftime('%Y%m%d_%H%M')}.csv"
    
    async def generate_csv():
        output = io.StringIO()
        writer = csv.writer(output)
        writer.writerow(["ID", "ç¾¤ç»„", "å‘é€è€…", "å†…å®¹", "æ—¶é—´", "åª’ä½“ç±»å‹", "è½¬å‘"])
        yield output.getvalue()
        output.truncate(0)
        output.seek(0)
        
        chunk_size = 500
        for i in range(0, len(rows), chunk_size):
            chunk = rows[i:i + chunk_size]
            for r in chunk:
                writer.writerow([
                    r["id"], r.get("group_title", ""), r.get("sender_name", ""),
                    (r.get("text") or "")[:500], r.get("date", ""),
                    r.get("media_type", ""), r.get("forward_from", ""),
                ])
            yield output.getvalue()
            output.truncate(0)
            output.seek(0)

    return StreamingResponse(
        generate_csv(),
        media_type="text/csv",
        headers={"Content-Disposition": f"attachment; filename={filename}"},
    )


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# æ‘˜è¦ç›¸å…³ API
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

import asyncio
import uuid
import httpx
from .summarizer import Summarizer

# å¼‚æ­¥ä»»åŠ¡è¿½è¸ª
_summary_tasks: dict = {}  # task_id -> {status, progress, result, error, ...}


def _cleanup_summary_tasks():
    """æ¸…ç†è¶…æœŸï¼ˆè¶…è¿‡1å°æ—¶çš„å®Œæˆä»»åŠ¡æˆ–è¶…è¿‡6å°æ—¶çš„è¿è¡Œä»»åŠ¡ï¼‰é¿å…å†…å­˜æ³„æ¼"""
    now = datetime.now(timezone.utc)
    to_delete = []
    for tid, task in _summary_tasks.items():
        started_str = task.get("started_at", now.isoformat(timespec='seconds'))
        try:
            started = datetime.fromisoformat(started_str.replace("Z", "+00:00"))
            if started.tzinfo is None:
                started = started.replace(tzinfo=timezone.utc)
        except Exception:
            started = now
            
        is_finished = task.get("status") in ("done", "error")
        age_hours = (now - started).total_seconds() / 3600
        if (is_finished and age_hours > 1) or (not is_finished and age_hours > 6):
            to_delete.append(tid)
    for tid in to_delete:
        del _summary_tasks[tid]


@app.get("/api/llm/status")
async def api_llm_status():
    """æ£€æµ‹ LLM ä»£ç†è¿æ¥çŠ¶æ€"""
    config = _config or load_config()
    ai_cfg = config.get("ai", {})
    api_url = ai_cfg.get("api_url", "")
    model = ai_cfg.get("model", "?")

    if not api_url:
        return {"ok": False, "error": "æœªé…ç½® ai.api_url", "url": "", "model": model}

    # å°è¯•è¯·æ±‚ /v1/models ç«¯ç‚¹æ£€æµ‹è¿é€šæ€§
    base_url = api_url.rsplit("/v1/", 1)[0] if "/v1/" in api_url else api_url.rsplit("/", 1)[0]
    test_url = f"{base_url}/v1/models"

    try:
        api_key = ai_cfg.get("api_key", "")
        headers = {}
        if api_key:
            headers["Authorization"] = f"Bearer {api_key}"
        async with httpx.AsyncClient(timeout=8) as client:
            resp = await client.get(test_url, headers=headers)
            if resp.status_code == 200:
                return {"ok": True, "url": api_url, "model": model, "test_url": test_url}
            else:
                return {"ok": False, "error": f"HTTP {resp.status_code}", "url": api_url, "model": model}
    except httpx.ConnectError:
        return {"ok": False, "error": "è¿æ¥è¢«æ‹’ç»ï¼ˆä»£ç†æœªè¿è¡Œï¼‰", "url": api_url, "model": model}
    except httpx.TimeoutException:
        return {"ok": False, "error": "è¿æ¥è¶…æ—¶", "url": api_url, "model": model}
    except Exception as e:
        return {"ok": False, "error": str(e)[:200], "url": api_url, "model": model}


@app.post("/api/summary/generate")
async def api_summary_generate(
    hours: int = Query(default=24, ge=1, le=720),
    mode: str = Query(default="quick", regex="^(quick|per_group)$"),
):
    """è§¦å‘æ‘˜è¦ç”Ÿæˆï¼ˆå¼‚æ­¥ä»»åŠ¡ï¼Œè¿”å› task_id ç”¨äºè½®è¯¢è¿›åº¦ï¼‰"""
    config = _config or load_config()
    db = await get_db()

    # è§¦å‘å‰å…ˆæ¸…ç†è¿‡æœŸä»»åŠ¡é‡Šæ”¾å†…å­˜
    _cleanup_summary_tasks()

    task_id = str(uuid.uuid4())[:8]
    _summary_tasks[task_id] = {
        "status": "running",
        "progress": "æ­£åœ¨åˆå§‹åŒ–...",
        "current_step": 0,
        "total_steps": 10,
        "result": None,
        "error": None,
        "hours": hours,
        "mode": mode,
        "started_at": datetime.now(timezone.utc).isoformat(timespec='seconds'),
    }

    async def _run_summary():
        try:
            summarizer = Summarizer(config, db)
            
            async def progress_cb(text, current, total):
                _summary_tasks[task_id]["progress"] = text
                _summary_tasks[task_id]["current_step"] = current
                _summary_tasks[task_id]["total_steps"] = total
                logger.info(f"Task {task_id} Progress: {text} ({current}/{total})")

            if mode == "per_group":
                result = await summarizer.summarize_per_group(hours=hours, save=True, progress_cb=progress_cb)
            else:
                result = await summarizer.summarize(hours=hours, save=True, progress_cb=progress_cb)

            if result and not result.startswith("âŒ"):
                _summary_tasks[task_id]["status"] = "done"
                _summary_tasks[task_id]["result"] = result
                # æœ€åçš„ msg_count æ›´æ–°ï¼ˆå¯é€‰ï¼‰
                _summary_tasks[task_id]["msg_count"] = await db.get_message_count(
                    since=(datetime.now(timezone.utc) - timedelta(hours=hours)).isoformat(timespec='seconds')
                )
            else:
                _summary_tasks[task_id]["status"] = "error"
                _summary_tasks[task_id]["error"] = result or "LLM è¿”å›ç©ºç»“æœï¼Œè¯·æ£€æŸ¥ AI ä»£ç†æ˜¯å¦åœ¨çº¿"

        except Exception as e:
            logger.error(f"æ‘˜è¦ç”Ÿæˆå¤±è´¥: {e}", exc_info=True)
            _summary_tasks[task_id]["status"] = "error"
            _summary_tasks[task_id]["error"] = f"{type(e).__name__}: {str(e)[:300]}"

    asyncio.create_task(_run_summary())
    return {"task_id": task_id, "status": "running"}


@app.get("/api/summary/status/{task_id}")
async def api_summary_status(task_id: str):
    """æŸ¥è¯¢æ‘˜è¦ç”Ÿæˆä»»åŠ¡çŠ¶æ€"""
    task = _summary_tasks.get(task_id)
    if not task:
        return {"status": "not_found", "error": "ä»»åŠ¡ä¸å­˜åœ¨æˆ–å·²è¿‡æœŸ"}
    return task


@app.get("/api/summary/history")
async def api_summary_history(limit: int = Query(default=10, le=50)):
    """è·å–å†å²æ‘˜è¦"""
    db = await get_db()
    summaries = await db.get_latest_summaries(limit=limit)
    return {"data": summaries}


def run_dashboard(config_path=None, host="0.0.0.0", port=8501):
    """å¯åŠ¨ Dashboard"""
    import uvicorn
    logging.basicConfig(
        level=logging.INFO,
        format="%(asctime)s [%(name)s] %(levelname)s: %(message)s",
        datefmt="%H:%M:%S",
    )
    uvicorn.run("src.dashboard:app", host=host, port=port, reload=False)


if __name__ == "__main__":
    run_dashboard()
