"""
æ•°æ®åº“æ¨¡å—
ä½¿ç”¨ SQLite å­˜å‚¨ç¾¤èŠæ¶ˆæ¯ã€é“¾æ¥å’Œæ‘˜è¦
"""
from __future__ import annotations

import asyncio
import json
import re
from datetime import datetime, timezone, timedelta
from pathlib import Path
from typing import Any, Dict, List, Optional

import aiosqlite
import logging

logger = logging.getLogger("tg-monitor.database")

# URL æå–æ­£åˆ™
URL_PATTERN = re.compile(
    r"https?://[^\s<>\"')\]ï¼Œã€‚ï¼ï¼Ÿã€ï¼›ï¼šï¼‰ã€‹ã€ã€ã€‘\u200b]+"
)

# ä¸å†ä½¿ç”¨ç¡¬ç¼–ç åŸŸåè¿‡æ»¤ï¼Œæ”¹ä¸ºåœ¨æ–¹æ³•ä¸­åŠ¨æ€ä½¿ç”¨å‚æ•°åŒ–æŸ¥è¯¢

SCHEMA_SQL = """
CREATE TABLE IF NOT EXISTS groups (
    id           INTEGER PRIMARY KEY,
    title        TEXT NOT NULL,
    username     TEXT,
    member_count INTEGER,
    updated_at   TEXT NOT NULL
);

CREATE TABLE IF NOT EXISTS messages (
    id           INTEGER NOT NULL,
    group_id     INTEGER NOT NULL,
    sender_id    INTEGER,
    sender_name  TEXT,
    text         TEXT,
    date         TEXT NOT NULL,
    media_type   TEXT,
    forward_from TEXT,
    reply_to_id  INTEGER,
    raw_json     TEXT,
    created_at   TEXT NOT NULL DEFAULT (datetime('now')),
    PRIMARY KEY (id, group_id)
);

CREATE TABLE IF NOT EXISTS links (
    id           INTEGER PRIMARY KEY AUTOINCREMENT,
    url          TEXT NOT NULL,
    message_id   INTEGER NOT NULL,
    group_id     INTEGER NOT NULL,
    sender_name  TEXT,
    context      TEXT,
    discovered_at TEXT NOT NULL
);

CREATE TABLE IF NOT EXISTS summaries (
    id           INTEGER PRIMARY KEY AUTOINCREMENT,
    group_id     INTEGER,
    period_start TEXT NOT NULL,
    period_end   TEXT NOT NULL,
    message_count INTEGER NOT NULL,
    content      TEXT NOT NULL,
    model        TEXT,
    created_at   TEXT NOT NULL DEFAULT (datetime('now'))
);

CREATE INDEX IF NOT EXISTS idx_messages_group_date ON messages(group_id, date);
CREATE INDEX IF NOT EXISTS idx_messages_date ON messages(date);
CREATE INDEX IF NOT EXISTS idx_links_group ON links(group_id, discovered_at);
CREATE INDEX IF NOT EXISTS idx_summaries_period ON summaries(period_start, period_end);

-- é“¾æ¥å»é‡ç´¢å¼•
CREATE UNIQUE INDEX IF NOT EXISTS idx_links_unique
    ON links(url, group_id, message_id);

CREATE INDEX IF NOT EXISTS idx_links_url ON links(url);

CREATE TABLE IF NOT EXISTS alerted_messages (
    msg_key      TEXT PRIMARY KEY,
    alerted_at   TEXT NOT NULL DEFAULT (datetime('now'))
);
"""

# FTS5 å…¨æ–‡æœç´¢ï¼ˆåˆ†ä¸ºç‹¬ç«‹è¯­å¥ï¼Œé¿å… executescript çš„æ’ä»–é”ï¼‰
FTS_CREATE_SQL = """CREATE VIRTUAL TABLE IF NOT EXISTS messages_fts USING fts5(
    text,
    sender_name,
    content='messages',
    content_rowid='rowid'
)"""

FTS_TRIGGER_SQL = """CREATE TRIGGER IF NOT EXISTS messages_ai AFTER INSERT ON messages BEGIN
    INSERT INTO messages_fts(rowid, text, sender_name)
    VALUES (new.rowid, new.text, new.sender_name);
END"""

# FTS5 UPDATE è§¦å‘å™¨ï¼šæ¶ˆæ¯ç¼–è¾‘æ—¶åŒæ­¥æ›´æ–°å…¨æ–‡ç´¢å¼•
FTS_TRIGGER_UPDATE_SQL = """CREATE TRIGGER IF NOT EXISTS messages_au AFTER UPDATE ON messages
WHEN new.text IS NOT old.text BEGIN
    INSERT INTO messages_fts(messages_fts, rowid, text, sender_name)
    VALUES ('delete', old.rowid, old.text, old.sender_name);
    INSERT INTO messages_fts(rowid, text, sender_name)
    VALUES (new.rowid, new.text, new.sender_name);
END"""

# â”€â”€â”€ P1#8: å¢é‡è¿ç§»ç³»ç»Ÿ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# æ¯ä¸ªå…ƒç´ ä¸º (version: int, description: str, sql: str)
# version å¿…é¡»å•è°ƒé€’å¢ã€ä¸å¾—ä¿®æ”¹å·²ç»å‘å¸ƒçš„ versionã€‚
MIGRATIONS: list[tuple[int, str, str]] = [
    (
        1,
        "Add alerted_messages table for alert deduplication",
        """CREATE TABLE IF NOT EXISTS alerted_messages (
            msg_key    TEXT PRIMARY KEY,
            alerted_at TEXT NOT NULL DEFAULT (datetime('now'))
        )""",
    ),
    # æœªæ¥æ–°å¢å­—æ®µç¤ºä¾‹ï¼ˆæ³¨é‡Šæ‰ï¼‰ï¼š
    # (
    #     2,
    #     "Add sentiment column to messages",
    #     "ALTER TABLE messages ADD COLUMN sentiment TEXT",
    # ),
]


class Database:
    """å¼‚æ­¥ SQLite æ•°æ®åº“ç®¡ç†å™¨"""

    def __init__(self, db_path: str):
        self.db_path = db_path
        self._db: Optional[aiosqlite.Connection] = None

    async def connect(self):
        """è¿æ¥æ•°æ®åº“å¹¶åˆå§‹åŒ– schema"""
        Path(self.db_path).parent.mkdir(parents=True, exist_ok=True)
        self._db = await aiosqlite.connect(self.db_path)
        self._db.row_factory = aiosqlite.Row
        # é˜²æ­¢å¹¶å‘é”å†²çªï¼ˆç­‰å¾… 5 ç§’ï¼‰
        await self._db.execute("PRAGMA busy_timeout=5000")
        # å¼€å¯ WAL æ¨¡å¼ï¼šæå‡å¹¶å‘æ€§èƒ½å’Œå´©æºƒæ¢å¤èƒ½åŠ›
        await self._db.execute("PRAGMA journal_mode=WAL")
        # â”€â”€ æ€§èƒ½è°ƒä¼˜ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
        # 32 MB é¡µç¼“å­˜ï¼šå‡å°‘çƒ­æ•°æ®æŸ¥è¯¢çš„ç£ç›˜ I/Oï¼ˆå¯¹æ‘˜è¦ã€ç»Ÿè®¡ã€æœç´¢æŸ¥è¯¢æ•ˆæœæ˜¾è‘—ï¼‰
        await self._db.execute("PRAGMA cache_size = -32000")
        # ä¸´æ—¶è¡¨ï¼ˆORDER BY/GROUP BY ä¸­é—´ç»“æœï¼‰æ”¾å†…å­˜ï¼Œé¿å…è½ç›˜
        await self._db.execute("PRAGMA temp_store = MEMORY")
        # WAL æ¨¡å¼ä¸‹ NORMAL åŒæ­¥è¶³å¤Ÿå®‰å…¨ï¼ˆFULL æ˜¯ WAL ä»¥å¤–æ¨¡å¼æ‰éœ€è¦ï¼‰
        await self._db.execute("PRAGMA synchronous = NORMAL")
        # WAL æ–‡ä»¶è¶…è¿‡ 1000 é¡µæ—¶è‡ªåŠ¨ checkpointï¼Œé˜²æ­¢ WAL æ— é™è†¨èƒ€æ‹–æ…¢å†™å…¥
        await self._db.execute("PRAGMA wal_autocheckpoint = 1000")
        # é€æ¡æ‰§è¡Œ schemaï¼ˆé¿å… executescript çš„æ’ä»–é”ï¼‰
        for stmt in SCHEMA_SQL.split(";"):
            stmt = stmt.strip()
            if not stmt:
                continue
            try:
                await self._db.execute(stmt)
            except aiosqlite.OperationalError as e:
                # åªå¿½ç•¥ã€Œå·²å­˜åœ¨ã€ç±»å‹çš„é”™è¯¯ï¼Œå…¶ä»–é”™è¯¯ï¼ˆç£ç›˜æ»¡ã€æƒé™ç­‰ï¼‰éœ€è¦æŠ›å‡º
                if "already exists" not in str(e).lower():
                    logger.error(f"âŒ Schema åˆå§‹åŒ–å¤±è´¥: {e}\nSQL: {stmt[:120]}")
                    raise
            except aiosqlite.IntegrityError as e:
                # UNIQUE INDEX åˆ›å»ºæ—¶ï¼Œè‹¥å·²æœ‰é‡å¤æ•°æ®ä¼šè§¦å‘ IntegrityError
                # å…ˆå»é‡ï¼Œå†é‡è¯•åˆ›å»ºç´¢å¼•
                if "idx_links_unique" in stmt:
                    logger.warning("âš ï¸ links è¡¨å­˜åœ¨é‡å¤æ•°æ®ï¼Œæ­£åœ¨å»é‡åé‡å»ºå”¯ä¸€ç´¢å¼•...")
                    await self._db.execute("""
                        DELETE FROM links WHERE rowid NOT IN (
                            SELECT MIN(rowid) FROM links
                            GROUP BY url, group_id, message_id
                        )
                    """)
                    await self._db.commit()
                    await self._db.execute(stmt)  # å»é‡åé‡è¯•
                    logger.info("âœ… links è¡¨å»é‡å®Œæˆï¼Œå”¯ä¸€ç´¢å¼•å·²å»ºç«‹")
                else:
                    logger.warning(f"âš ï¸ Schema è¯­å¥è·³è¿‡ï¼ˆIntegrityErrorï¼‰: {e}\nSQL: {stmt[:120]}")
        await self._db.commit()
        # åˆå§‹åŒ– FTS5 å…¨æ–‡æœç´¢
        try:
            await self._db.execute(FTS_CREATE_SQL)
            await self._db.execute(FTS_TRIGGER_SQL)
            await self._db.execute(FTS_TRIGGER_UPDATE_SQL)
            await self._db.commit()
            # æ£€æŸ¥æ˜¯å¦éœ€è¦é‡å»ºç´¢å¼•ï¼ˆé¦–æ¬¡åˆ›å»º FTS è¡¨æ—¶ï¼‰
            cursor = await self._db.execute(
                "SELECT COUNT(*) as cnt FROM messages_fts"
            )
            fts_count = (await cursor.fetchone())["cnt"]
            cursor2 = await self._db.execute(
                "SELECT COUNT(*) as cnt FROM messages WHERE text IS NOT NULL"
            )
            msg_count = (await cursor2.fetchone())["cnt"]
            if fts_count == 0 and msg_count > 0:
                logger.info(f"ğŸ”„ é‡å»º FTS ç´¢å¼• ({msg_count} æ¡æ¶ˆæ¯)...")
                await self._db.execute(
                    "INSERT INTO messages_fts(messages_fts) VALUES('rebuild')"
                )
                await self._db.commit()  # P0 ä¿®å¤ï¼šé‡å»ºåå¿…é¡» commit æ‰èƒ½è½ç›˜
                logger.info("âœ… FTS ç´¢å¼•é‡å»ºå®Œæˆ")
        except Exception as e:
            logger.warning(f"âš ï¸ FTS5 åˆå§‹åŒ–å¤±è´¥ï¼ˆå›é€€åˆ° LIKE æœç´¢ï¼‰: {e}")
        # åˆå§‹åŒ–å¹¶è¿è¡Œå¢é‡è¿ç§»ï¼ˆP1#8ï¼‰
        await self._run_migrations()
        logger.info("âœ… æ•°æ®åº“å·²è¿æ¥ (WAL æ¨¡å¼)")

    async def _run_migrations(self):
        """è¿è¡Œå¢é‡è¿ç§»ï¼ˆP1#8ï¼‰ã€‚
        - åˆ›å»º schema_version å…ƒæ•°æ®è¡¨ï¼ˆè‹¥ä¸å­˜åœ¨ï¼‰
        - æŒ‰ version é¡ºåºåº”ç”¨å°šæœªæ‰§è¡Œè¿‡çš„è¿ç§»
        - æ¯æ¬¡è¿ç§»æ‰§è¡Œåç«‹å³å†…åµŒ commitï¼Œç¡®ä¿åŸå­æ€§
        """
        # ç¡®ä¿å…ƒæ•°æ®è¡¨å­˜åœ¨
        await self._db.execute(
            """CREATE TABLE IF NOT EXISTS schema_version (
                version    INTEGER PRIMARY KEY,
                applied_at TEXT NOT NULL DEFAULT (datetime('now')),
                description TEXT
            )"""
        )
        await self._db.commit()

        # è¯»å–å·²åº”ç”¨çš„æœ€é«˜ç‰ˆæœ¬
        cursor = await self._db.execute(
            "SELECT COALESCE(MAX(version), 0) as ver FROM schema_version"
        )
        current = (await cursor.fetchone())["ver"]

        pending = [(v, d, s) for v, d, s in MIGRATIONS if v > current]
        if not pending:
            return

        logger.info(f"ğŸ”„ åº”ç”¨ {len(pending)} ä¸ªè¿ç§»ï¼ˆå½“å‰ç‰ˆæœ¬: {current}ï¼‰...")
        for version, description, sql in sorted(pending, key=lambda x: x[0]):
            try:
                await self._db.execute(sql)
                await self._db.execute(
                    "INSERT OR IGNORE INTO schema_version (version, description) VALUES (?, ?)",
                    (version, description),
                )
                await self._db.commit()
                logger.info(f"   âœ… v{version}: {description}")
            except (aiosqlite.OperationalError, aiosqlite.IntegrityError) as e:
                # å¦‚æœè¡¨/åˆ—å·²å­˜åœ¨ï¼Œè§†ä¸ºå·²åº”ç”¨æˆåŠŸ
                if "already exists" in str(e).lower() or "duplicate" in str(e).lower():
                    await self._db.execute(
                        "INSERT OR IGNORE INTO schema_version (version, description) VALUES (?, ?)",
                        (version, description),
                    )
                    await self._db.commit()
                    logger.info(f"   âš ï¸ v{version}: å·²å­˜åœ¨ï¼Œè·³è¿‡")
                else:
                    logger.error(f"   âŒ v{version} è¿ç§»å¤±è´¥: {e}")
                    raise

    async def close(self):
        if self._db:
            await self._db.close()

    # â”€â”€â”€ ç¾¤ç»„æ“ä½œ â”€â”€â”€

    async def upsert_group(
        self, group_id: int, title: str, username: Optional[str] = None,
        member_count: Optional[int] = None
    ):
        now = datetime.now(timezone.utc).isoformat(timespec='seconds')
        await self._db.execute(
            """INSERT INTO groups (id, title, username, member_count, updated_at)
               VALUES (?, ?, ?, ?, ?)
               ON CONFLICT(id) DO UPDATE SET
                 title = excluded.title,
                 username = excluded.username,
                 member_count = excluded.member_count,
                 updated_at = excluded.updated_at""",
            (group_id, title, username, member_count, now),
        )
        await self._db.commit()

    async def get_groups(self) -> List[dict]:
        cursor = await self._db.execute("SELECT * FROM groups ORDER BY title")
        rows = await cursor.fetchall()
        return [dict(r) for r in rows]

    # â”€â”€â”€ æ¶ˆæ¯æ“ä½œ â”€â”€â”€

    async def insert_message(self, msg: dict):
        """æ’å…¥å•æ¡æ¶ˆæ¯ï¼ŒåŒæ—¶è‡ªåŠ¨æå–é“¾æ¥ã€‚å¤±è´¥æ—¶è®°å½•æ—¥å¿—ä½†ä¸ä¸­æ–­ã€‚"""
        try:
            await self._db.execute(
                """INSERT OR IGNORE INTO messages
                   (id, group_id, sender_id, sender_name, text, date,
                    media_type, forward_from, reply_to_id, raw_json)
                   VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?)""",
                (
                    msg["id"], msg["group_id"], msg.get("sender_id"),
                    msg.get("sender_name"), msg.get("text"), msg["date"],
                    msg.get("media_type"), msg.get("forward_from"),
                    msg.get("reply_to_id"), msg.get("raw_json"),
                ),
            )

            # è‡ªåŠ¨æå–é“¾æ¥
            if msg.get("text"):
                urls = URL_PATTERN.findall(msg["text"])
                for url in urls:
                    await self._db.execute(
                        """INSERT OR IGNORE INTO links (url, message_id, group_id, sender_name,
                                             context, discovered_at)
                           VALUES (?, ?, ?, ?, ?, ?)""",
                        (
                            url, msg["id"], msg["group_id"],
                            msg.get("sender_name"),
                            msg["text"][:200],
                            msg["date"],
                        ),
                    )

            await self._db.commit()
        except Exception as e:
            logger.error(
                f"âŒ æ’å…¥æ¶ˆæ¯å¤±è´¥ (msg_id={msg.get('id')}, "
                f"group_id={msg.get('group_id')}): {e}"
            )

    async def insert_messages_batch(self, messages: List[dict]):
        """æ‰¹é‡æ’å…¥æ¶ˆæ¯ï¼ˆå•äº‹åŠ¡ï¼Œæ€§èƒ½è¿œä¼˜äºé€æ¡ commitï¼‰"""
        if not messages:
            return
        try:
            for msg in messages:
                await self._db.execute(
                    """INSERT OR IGNORE INTO messages
                       (id, group_id, sender_id, sender_name, text, date,
                        media_type, forward_from, reply_to_id, raw_json)
                       VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?)""",
                    (
                        msg["id"], msg["group_id"], msg.get("sender_id"),
                        msg.get("sender_name"), msg.get("text"), msg["date"],
                        msg.get("media_type"), msg.get("forward_from"),
                        msg.get("reply_to_id"), msg.get("raw_json"),
                    ),
                )
                # æå–é“¾æ¥
                if msg.get("text"):
                    urls = URL_PATTERN.findall(msg["text"])
                    for url in urls:
                        await self._db.execute(
                            """INSERT OR IGNORE INTO links (url, message_id, group_id,
                                                 sender_name, context, discovered_at)
                               VALUES (?, ?, ?, ?, ?, ?)""",
                            (
                                url, msg["id"], msg["group_id"],
                                msg.get("sender_name"),
                                msg["text"][:200],
                                msg["date"],
                            ),
                        )
            await self._db.commit()
            logger.info(f"âœ… æ‰¹é‡æ’å…¥ {len(messages)} æ¡æ¶ˆæ¯")
        except Exception as e:
            logger.error(f"âŒ æ‰¹é‡æ’å…¥å¤±è´¥: {e}")

    async def get_messages(
        self,
        group_id: Optional[int] = None,
        since: Optional[str] = None,
        until: Optional[str] = None,
        limit: Optional[int] = None,
    ) -> List[dict]:
        """æŸ¥è¯¢æ¶ˆæ¯ï¼ˆæŒ‰æ—¶é—´èŒƒå›´ï¼Œé»˜è®¤ä¸é™æ¡æ•°ï¼‰"""
        conditions = []
        params: List[Any] = []

        if group_id is not None:
            conditions.append("group_id = ?")
            params.append(group_id)
        if since:
            conditions.append("date >= ?")
            params.append(since)
        if until:
            conditions.append("date <= ?")
            params.append(until)

        where = "WHERE " + " AND ".join(conditions) if conditions else ""
        limit_clause = f"LIMIT {limit}" if limit else ""
        query = f"SELECT * FROM messages {where} ORDER BY date ASC {limit_clause}"

        cursor = await self._db.execute(query, params)
        rows = await cursor.fetchall()
        return [dict(r) for r in rows]

    async def get_message_count(
        self,
        group_id: Optional[int] = None,
        since: Optional[str] = None,
        until: Optional[str] = None,
    ) -> int:
        conditions: List[str] = []
        params: List[Any] = []
        if group_id is not None:
            conditions.append("group_id = ?")
            params.append(group_id)
        if since:
            conditions.append("date >= ?")
            params.append(since)
        if until:
            conditions.append("date <= ?")
            params.append(until)

        where = "WHERE " + " AND ".join(conditions) if conditions else ""
        cursor = await self._db.execute(
            f"SELECT COUNT(*) as cnt FROM messages {where}", params
        )
        row = await cursor.fetchone()
        return row["cnt"]

    async def search_messages(self, keyword: str, limit: int = 50) -> List[dict]:
        """å…¨æ–‡æœç´¢æ¶ˆæ¯ï¼ˆä¼˜å…ˆä½¿ç”¨ FTS5ï¼Œå›é€€åˆ° LIKEï¼‰"""
        try:
            # å°è¯• FTS5 æœç´¢
            cursor = await self._db.execute(
                """SELECT m.*, g.title as group_title
                   FROM messages m
                   JOIN messages_fts fts ON m.rowid = fts.rowid
                   LEFT JOIN groups g ON m.group_id = g.id
                   WHERE messages_fts MATCH ?
                   ORDER BY m.date DESC LIMIT ?""",
                (keyword, limit),
            )
            rows = await cursor.fetchall()
            return [dict(r) for r in rows]
        except Exception:
            # å›é€€åˆ° LIKE æœç´¢
            cursor = await self._db.execute(
                """SELECT m.*, g.title as group_title
                   FROM messages m
                   LEFT JOIN groups g ON m.group_id = g.id
                   WHERE m.text LIKE ?
                   ORDER BY m.date DESC LIMIT ?""",
                (f"%{keyword}%", limit),
            )
            rows = await cursor.fetchall()
            return [dict(r) for r in rows]

    # â”€â”€â”€ é“¾æ¥æ“ä½œ â”€â”€â”€

    async def get_links(
        self,
        group_id: Optional[int] = None,
        limit: int = 20,
        block_domains: Optional[List[str]] = None,
    ) -> List[dict]:
        conditions: List[str] = []
        params: List[Any] = []
        
        if block_domains:
            for domain in block_domains:
                conditions.append("LOWER(l.url) NOT LIKE ?")
                params.append(f"%{domain.lower()}%")
                
        if group_id is not None:
            conditions.append("l.group_id = ?")
            params.append(group_id)

        where = "WHERE " + " AND ".join(conditions) if conditions else ""
        cursor = await self._db.execute(
            f"""SELECT l.*, g.title as group_title
                FROM links l
                LEFT JOIN groups g ON l.group_id = g.id
                {where}
                ORDER BY l.discovered_at DESC LIMIT ?""",
            [*params, limit],
        )
        rows = await cursor.fetchall()
        return [dict(r) for r in rows]

    async def get_links_aggregated(
        self,
        limit: int = 50,
        block_domains: Optional[List[str]] = None,
    ) -> List[dict]:
        """æŒ‰ URL èšåˆé“¾æ¥ï¼Œç»Ÿè®¡å‡ºç°æ¬¡æ•°ã€æ¥æºç¾¤ç»„å’Œå‘é€è€…"""
        conditions: List[str] = ["1=1"]
        params: List[Any] = []
        
        if block_domains:
            for domain in block_domains:
                conditions.append("LOWER(l.url) NOT LIKE ?")
                params.append(f"%{domain.lower()}%")

        where = " AND ".join(conditions)
        cursor = await self._db.execute(
            f"""SELECT
                  l.url,
                  COUNT(*) as total_count,
                  COUNT(DISTINCT l.group_id) as group_count,
                  GROUP_CONCAT(DISTINCT g.title) as group_titles,
                  GROUP_CONCAT(DISTINCT l.sender_name) as sender_names,
                  MIN(l.discovered_at) as first_seen,
                  MAX(l.discovered_at) as last_seen
               FROM links l
               LEFT JOIN groups g ON l.group_id = g.id
               WHERE {where}
               GROUP BY l.url
               ORDER BY total_count DESC, last_seen DESC
               LIMIT ?""",
            [*params, limit],
        )
        rows = await cursor.fetchall()
        return [dict(r) for r in rows]

    # â”€â”€â”€ å‘Šè­¦å»é‡æŒä¹…åŒ– â”€â”€â”€

    async def add_alerted_message(self, msg_key: str):
        """è®°å½•å·²å‘Šè­¦çš„æ¶ˆæ¯ keyï¼Œé˜²æ­¢é‡å¯åé‡å¤æ¨é€"""
        try:
            await self._db.execute(
                "INSERT OR IGNORE INTO alerted_messages (msg_key) VALUES (?)",
                (msg_key,),
            )
            await self._db.commit()
        except Exception as e:
            logger.warning(f"âš ï¸ å†™å…¥å‘Šè­¦è®°å½•å¤±è´¥: {e}")

    async def get_recent_alerted_ids(self, hours: int = 24) -> set:
        """åŠ è½½æœ€è¿‘ N å°æ—¶å†…å·²å‘Šè­¦çš„ msg_key é›†åˆï¼ˆè¿›ç¨‹é‡å¯åæ¢å¤å»é‡çŠ¶æ€ï¼‰"""
        try:
            since = (datetime.now(timezone.utc) - timedelta(hours=hours)).isoformat(timespec='seconds')
            cursor = await self._db.execute(
                "SELECT msg_key FROM alerted_messages WHERE alerted_at >= ?",
                (since,),
            )
            rows = await cursor.fetchall()
            return {row["msg_key"] for row in rows}
        except Exception as e:
            logger.warning(f"âš ï¸ è¯»å–å‘Šè­¦è®°å½•å¤±è´¥: {e}")
            return set()

    async def cleanup_old_alerts(self, keep_hours: int = 48):
        """æ¸…ç†è¶…æœŸå‘Šè­¦è®°å½•ï¼Œé˜²æ­¢è¡¨æ— é™å¢é•¿"""
        try:
            cutoff = (datetime.now(timezone.utc) - timedelta(hours=keep_hours)).isoformat(timespec='seconds')
            await self._db.execute(
                "DELETE FROM alerted_messages WHERE alerted_at < ?",
                (cutoff,),
            )
            await self._db.commit()
        except Exception as e:
            logger.warning(f"âš ï¸ æ¸…ç†å‘Šè­¦è®°å½•å¤±è´¥: {e}")

    # â”€â”€â”€ æ‘˜è¦æ“ä½œ â”€â”€â”€

    async def save_summary(
        self,
        group_id: Optional[int],
        period_start: str,
        period_end: str,
        message_count: int,
        content: str,
        model: Optional[str] = None,
    ):
        await self._db.execute(
            """INSERT INTO summaries
               (group_id, period_start, period_end, message_count, content, model)
               VALUES (?, ?, ?, ?, ?, ?)""",
            (group_id, period_start, period_end, message_count, content, model),
        )
        await self._db.commit()

    async def get_latest_summaries(self, limit: int = 10) -> List[dict]:
        cursor = await self._db.execute(
            """SELECT s.*, g.title as group_title
               FROM summaries s
               LEFT JOIN groups g ON s.group_id = g.id
               WHERE s.content NOT LIKE '%âš ï¸ æ‘˜è¦ç”Ÿæˆå¤±è´¥%' AND s.content NOT LIKE '%âŒ%'
               ORDER BY s.created_at DESC LIMIT ?""",
            (limit,),
        )
        rows = await cursor.fetchall()
        return [dict(r) for r in rows]

    # â”€â”€â”€ ç»Ÿè®¡ â”€â”€â”€

    async def get_stats(
        self, since: Optional[str] = None, until: Optional[str] = None,
    ) -> List[dict]:
        """æŒ‰ç¾¤ç»„ç»Ÿè®¡æ¶ˆæ¯æ•°å’Œæ´»è·ƒç”¨æˆ·æ•°"""
        conditions: List[str] = []
        params: List[Any] = []
        if since:
            conditions.append("m.date >= ?")
            params.append(since)
        if until:
            conditions.append("m.date <= ?")
            params.append(until)

        where = "WHERE " + " AND ".join(conditions) if conditions else ""
        cursor = await self._db.execute(
            f"""SELECT
                  g.title,
                  m.group_id,
                  COUNT(*) as message_count,
                  -- DB3 ä¿®å¤ï¼šsender_id ä¸º NULL æ—¶ï¼ˆåŒ¿åé¢‘é“æ¶ˆæ¯ï¼‰å›é€€åˆ° sender_name
                  -- é¿å… COUNT(DISTINCT NULL) å°†åŒ¿åå‘è¨€è€…å…¨éƒ¨æ¼è®¡
                  COUNT(DISTINCT COALESCE(CAST(m.sender_id AS TEXT), m.sender_name)) as active_users,
                  MIN(m.date) as first_msg,
                  MAX(m.date) as last_msg
                FROM messages m
                LEFT JOIN groups g ON m.group_id = g.id
                {where}
                GROUP BY m.group_id
                ORDER BY message_count DESC""",
            params,
        )
        rows = await cursor.fetchall()
        return [dict(r) for r in rows]

    async def get_top_senders(
        self,
        group_id: Optional[int] = None,
        since: Optional[str] = None,
        limit: int = 10,
    ) -> List[dict]:
        conditions: List[str] = []
        params: List[Any] = []
        if group_id is not None:
            conditions.append("group_id = ?")
            params.append(group_id)
        if since:
            conditions.append("date >= ?")
            params.append(since)

        where = "WHERE " + " AND ".join(conditions) if conditions else ""
        cursor = await self._db.execute(
            f"""SELECT sender_name, sender_id, COUNT(*) as msg_count
                FROM messages
                {where}
                GROUP BY sender_id
                ORDER BY msg_count DESC LIMIT ?""",
            [*params, limit],
        )
        rows = await cursor.fetchall()
        return [dict(r) for r in rows]

    async def get_date_range(
        self,
        since: Optional[str] = None,
        until: Optional[str] = None,
    ) -> dict:
        """è·å–æ¶ˆæ¯çš„å®é™…æ—¶é—´èŒƒå›´"""
        conditions: List[str] = []
        params: List[Any] = []
        if since:
            conditions.append("date >= ?")
            params.append(since)
        if until:
            conditions.append("date <= ?")
            params.append(until)

        where = "WHERE " + " AND ".join(conditions) if conditions else ""
        cursor = await self._db.execute(
            f"""SELECT MIN(date) as first_msg,
                       MAX(date) as last_msg,
                       COUNT(*) as total
                FROM messages {where}""",
            params,
        )
        row = await cursor.fetchone()
        return dict(row)

    # â”€â”€â”€ çƒ­åŠ›å›¾ & å¯¹æ¯” â”€â”€â”€

    async def get_heatmap_data(
        self, days: int = 30,
    ) -> List[dict]:
        """æŒ‰æ˜ŸæœŸÃ—å°æ—¶ç»Ÿè®¡æ¶ˆæ¯åˆ†å¸ƒï¼ˆç”¨äºæ´»è·ƒåº¦çƒ­åŠ›å›¾ï¼‰"""
        now = datetime.now(timezone.utc)
        since = (now - timedelta(days=days)).isoformat(timespec='seconds')
        cursor = await self._db.execute(
            """SELECT
                 CAST(strftime('%w', date) AS INTEGER) as dow,
                 CAST(strftime('%H', date) AS INTEGER) as hour,
                 COUNT(*) as count
               FROM messages
               WHERE date >= ?
               GROUP BY dow, hour
               ORDER BY dow, hour""",
            (since,),
        )
        rows = await cursor.fetchall()
        return [dict(r) for r in rows]

    async def get_hourly_comparison(
        self,
    ) -> dict:
        """ä»Šå¤© vs æ˜¨å¤©åŒæ—¶æ®µæ¶ˆæ¯é‡å¯¹æ¯”"""
        now = datetime.now(timezone.utc)
        today_start = now.replace(hour=0, minute=0, second=0, microsecond=0)
        yesterday_start = today_start - timedelta(days=1)

        # ä»Šå¤©æŒ‰å°æ—¶
        cursor_today = await self._db.execute(
            """SELECT CAST(strftime('%H', date) AS INTEGER) as hour,
                      COUNT(*) as count
               FROM messages WHERE date >= ?
               GROUP BY hour ORDER BY hour""",
            (today_start.isoformat(timespec='seconds'),),
        )
        today = [dict(r) for r in await cursor_today.fetchall()]

        # æ˜¨å¤©æŒ‰å°æ—¶
        cursor_yesterday = await self._db.execute(
            """SELECT CAST(strftime('%H', date) AS INTEGER) as hour,
                      COUNT(*) as count
               FROM messages WHERE date >= ? AND date < ?
               GROUP BY hour ORDER BY hour""",
            (yesterday_start.isoformat(timespec='seconds'), today_start.isoformat(timespec='seconds')),
        )
        yesterday = [dict(r) for r in await cursor_yesterday.fetchall()]

        return {"today": today, "yesterday": yesterday}

    async def get_group_messages(
        self,
        group_id: int,
        hours: int = 24,
        limit: int = 100,
    ) -> List[dict]:
        """è·å–æŒ‡å®šç¾¤ç»„çš„æœ€æ–°æ¶ˆæ¯"""
        now = datetime.now(timezone.utc)
        since = (now - timedelta(hours=hours)).isoformat(timespec='seconds')
        cursor = await self._db.execute(
            """SELECT m.*, g.title as group_title
               FROM messages m
               LEFT JOIN groups g ON m.group_id = g.id
               WHERE m.group_id = ? AND m.date >= ?
               ORDER BY m.date DESC LIMIT ?""",
            (group_id, since, limit),
        )
        rows = await cursor.fetchall()
        return [dict(r) for r in rows]

    async def get_group_trends(
        self,
        group_id: int,
        hours: int = 72,
    ) -> List[dict]:
        """è·å–æŒ‡å®šç¾¤ç»„çš„æ¶ˆæ¯è¶‹åŠ¿"""
        now = datetime.now(timezone.utc)
        since = (now - timedelta(hours=hours)).isoformat(timespec='seconds')
        cursor = await self._db.execute(
            """SELECT
                 strftime('%Y-%m-%dT%H:00:00', date) as hour,
                 COUNT(*) as count
               FROM messages
               WHERE group_id = ? AND date >= ?
               GROUP BY hour ORDER BY hour ASC""",
            (group_id, since),
        )
        rows = await cursor.fetchall()
        return [dict(r) for r in rows]

    async def export_messages(
        self,
        since: Optional[str] = None,
        until: Optional[str] = None,
        group_id: Optional[int] = None,
        limit: Optional[int] = None,  # D4 ä¿®å¤ï¼šæ”¯æŒæ¡æ•°ä¸Šé™ï¼Œé˜²æ­¢å…¨é‡å¯¼å‡º OOM
    ) -> List[dict]:
        """å¯¼å‡ºæ¶ˆæ¯æ•°æ®"""
        conditions = []
        params = []
        if group_id:
            conditions.append("m.group_id = ?")
            params.append(group_id)
        if since:
            conditions.append("m.date >= ?")
            params.append(since)
        if until:
            conditions.append("m.date <= ?")
            params.append(until)

        where = "WHERE " + " AND ".join(conditions) if conditions else ""
        limit_clause = f"LIMIT {int(limit)}" if limit else ""
        cursor = await self._db.execute(
            f"""SELECT m.id, m.group_id, g.title as group_title,
                       m.sender_name, m.text, m.date,
                       m.media_type, m.forward_from
                FROM messages m
                LEFT JOIN groups g ON m.group_id = g.id
                {where}
                ORDER BY m.date ASC {limit_clause}""",
            params,
        )
        rows = await cursor.fetchall()
        return [dict(r) for r in rows]

    async def get_message_trends(self, hours: int = 72) -> List[dict]:
        """æŒ‰å°æ—¶ç»Ÿè®¡æ¶ˆæ¯è¶‹åŠ¿ï¼ˆç”¨äº Dashboard /api/trendsï¼‰"""
        now = datetime.now(timezone.utc)
        since = (now - timedelta(hours=hours)).isoformat(timespec='seconds')
        cursor = await self._db.execute(
            """SELECT strftime('%Y-%m-%dT%H:00:00', date) as hour, COUNT(*) as count
               FROM messages WHERE date >= ?
               GROUP BY hour ORDER BY hour ASC""",
            (since,),
        )
        rows = await cursor.fetchall()
        return [dict(r) for r in rows]

    async def get_recent_messages(
        self,
        limit: int = 100,
        group_id: Optional[int] = None,
    ) -> List[dict]:
        """è·å–æœ€æ–° N æ¡æ¶ˆæ¯ï¼ˆç”¨äº Dashboard /api/recent_messagesï¼‰"""
        conditions = []
        params: List[Any] = []
        if group_id is not None:
            conditions.append("group_id = ?")
            params.append(group_id)
        where = "WHERE " + " AND ".join(conditions) if conditions else ""
        params.append(limit)
        cursor = await self._db.execute(
            f"SELECT * FROM messages {where} ORDER BY date DESC LIMIT ?",
            params,
        )
        rows = await cursor.fetchall()
        messages = [dict(r) for r in rows]
        messages.reverse()  # æ¢å¤æ—¶é—´æ­£åº
        return messages

    # â”€â”€â”€ æ¶ˆæ¯ç¼–è¾‘ / åˆ é™¤åŒæ­¥ â”€â”€â”€

    async def update_message_text(
        self,
        msg_id: int,
        group_id: int,
        new_text: Optional[str],
        media_type: Optional[str] = None,
    ) -> bool:
        """
        æ›´æ–°æ¶ˆæ¯æ–‡æœ¬ï¼ˆæ¶ˆæ¯è¢«ç¼–è¾‘æ—¶è°ƒç”¨ï¼‰ã€‚
        è¿”å› True è¡¨ç¤ºå®é™…æœ‰æ›´æ–°ï¼ŒFalse è¡¨ç¤ºæ¶ˆæ¯ä¸å­˜åœ¨æˆ–æ–‡æœ¬æœªå˜ã€‚
        FTS ç´¢å¼•ç”±æ•°æ®åº“è§¦å‘å™¨ï¼ˆmessages_auï¼‰è‡ªåŠ¨ç»´æŠ¤ã€‚
        """
        try:
            cursor = await self._db.execute(
                """UPDATE messages
                   SET text = ?, media_type = COALESCE(?, media_type)
                   WHERE id = ? AND group_id = ?
                   AND text IS NOT ?""",  # æ–‡æœ¬æœªå˜åˆ™è·³è¿‡ï¼Œé¿å…æ— æ•ˆå†™æ“ä½œ
                (new_text, media_type, msg_id, group_id, new_text),
            )
            await self._db.commit()
            changed = cursor.rowcount > 0
            if changed:
                logger.debug(f"âœï¸ æ¶ˆæ¯å·²æ›´æ–° (id={msg_id}, group={group_id})")
            return changed
        except Exception as e:
            logger.error(f"âŒ æ›´æ–°æ¶ˆæ¯å¤±è´¥ (id={msg_id}): {e}")
            return False

    async def delete_messages(
        self,
        msg_ids: List[int],
        group_id: int,
    ) -> int:
        """
        æ‰¹é‡åˆ é™¤æŒ‡å®šæ¶ˆæ¯ï¼ˆæ¶ˆæ¯è¢« Telegram åˆ é™¤æ—¶è°ƒç”¨ï¼‰ã€‚
        åŒæ­¥æ¸…ç† FTS ç´¢å¼•ï¼Œé¿å…å¹½çµæœç´¢ç»“æœã€‚
        è¿”å›å®é™…åˆ é™¤æ¡æ•°ã€‚
        """
        if not msg_ids:
            return 0
        try:
            placeholders = ",".join("?" * len(msg_ids))
            # å…ˆè·å– rowid ä»¥ä¾¿æ‰‹åŠ¨æ¸…ç† FTSï¼ˆè§¦å‘å™¨ä»…å¤„ç† UPDATEï¼ŒDELETE éœ€æ‰‹åŠ¨ï¼‰
            cursor = await self._db.execute(
                f"""SELECT rowid, text, sender_name FROM messages
                    WHERE id IN ({placeholders}) AND group_id = ?""",
                [*msg_ids, group_id],
            )
            existing = await cursor.fetchall()

            if not existing:
                return 0

            # ä» FTS ç´¢å¼•ä¸­åˆ é™¤ï¼ˆcontent table æ¨¡å¼éœ€æ‰‹åŠ¨ç»´æŠ¤ DELETEï¼‰
            for row in existing:
                try:
                    await self._db.execute(
                        """INSERT INTO messages_fts(messages_fts, rowid, text, sender_name)
                           VALUES ('delete', ?, ?, ?)""",
                        (row["rowid"], row["text"] or "", row["sender_name"] or ""),
                    )
                except Exception:
                    pass  # FTS æ¸…ç†å¤±è´¥ä¸ä¸­æ–­ä¸»æµç¨‹

            # ç‰©ç†åˆ é™¤æ¶ˆæ¯
            cursor2 = await self._db.execute(
                f"DELETE FROM messages WHERE id IN ({placeholders}) AND group_id = ?",
                [*msg_ids, group_id],
            )
            await self._db.commit()
            deleted = cursor2.rowcount
            logger.info(f"ğŸ—‘ï¸ å·²åˆ é™¤ {deleted} æ¡æ¶ˆæ¯ (group={group_id}, ids={msg_ids[:5]}{'...' if len(msg_ids)>5 else ''})")
            return deleted
        except Exception as e:
            logger.error(f"âŒ åˆ é™¤æ¶ˆæ¯å¤±è´¥ (group={group_id}): {e}")
            return 0

    # â”€â”€â”€ æ•°æ®æ¸…ç† â”€â”€â”€

    async def cleanup_old_messages(
        self,
        keep_days: int = 90,
    ) -> int:
        """
        æ¸…ç†è¶…æœŸæ¶ˆæ¯ï¼ˆé»˜è®¤ä¿ç•™ 90 å¤©ï¼‰ã€‚
        åŒæ­¥æ¸…ç†å…³è”çš„ links è®°å½•ã€‚
        è¿”å›åˆ é™¤æ¡æ•°ã€‚
        """
        cutoff = (datetime.now(timezone.utc) - timedelta(days=keep_days)).isoformat(timespec='seconds')
        try:
            # å…ˆæ¸…ç† linksï¼ˆå¤–é”®ä¾èµ– messages.idï¼‰
            await self._db.execute(
                "DELETE FROM links WHERE discovered_at < ?", (cutoff,)
            )
            cursor = await self._db.execute(
                "DELETE FROM messages WHERE date < ?", (cutoff,)
            )
            # FTS å†…å®¹è¡¨åœ¨ content= æ¨¡å¼ä¸‹éšç‰©ç†è¡¨åˆ é™¤ï¼Œé‡å»ºä¸€æ¬¡å³å¯
            await self._db.execute(
                "INSERT INTO messages_fts(messages_fts) VALUES('rebuild')"
            )
            await self._db.commit()
            deleted = cursor.rowcount
            logger.info(f"ğŸ§¹ æ¸…ç†è¶…æœŸæ¶ˆæ¯: {deleted} æ¡ (cutoff={cutoff[:10]})")
            return deleted
        except Exception as e:
            logger.error(f"âŒ æ¸…ç†æ¶ˆæ¯å¤±è´¥: {e}")
            return 0
